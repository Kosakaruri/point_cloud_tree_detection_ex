---
title: "UAS SfM Point Cloud Processing"
subtitle: "Tree Detection Example"
author: "Original Author: Neal Swayze | Adapted by: George Woolsey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
    # code_folding: hide
editor_options: 
  chunk_output_type: console
knit: (function(inputFile, encoding){ 
    out_dir <- '../';
    rmarkdown::render(inputFile, encoding = encoding, output_file=file.path(dirname(inputFile), out_dir, 'index.html')) 
  })
---

# Introduction

This script processes point cloud data in `las` or `laz` file format from Lidar or UAS structure from motion (SfM) data collection systems. Products created include:

* Classified points (ground/non-ground)
* Digital terrain model (DTM)
* Normalized point cloud (i.e. point height above ground surface)
* Canopy height model (CHM; raster)
* Individual tree locations and heights (points)
* Individual tree crown extents (polygons)
* Individual tree DBH estimates
* ~~Local competition metrics, including the distance to the nearest neighbor, trees ha^-1^ within a 5m radius, and the relative tree height within a 5m radius~~

This script incorporates and builds upon the techniques outlined in research including:

* *[Modeling the Missing DBHs: Influence of Model Form on UAV DBH Characterization](https://scholar.google.com/scholar?cluster=14807895789640069059&hl=en&as_sdt=0,6)* (Tinkham et al. 2022)
* *[Application of unmanned aerial system structure from motion point cloud detected tree heights and stem diameters to model missing stem diameters](https://scholar.google.com/scholar?cluster=10655866445299954513&hl=en&as_sdt=0,6)* (Swayze and Tinkham 2022)
* *[Influence of flight parameters on UAS-based monitoring of tree height, diameter, and density](https://scholar.google.com/scholar?cluster=12684146395735544399&hl=en&as_sdt=0,6)* (Swayze et al. 2022)
* *[Potential for individual tree monitoring in ponderosa pine dominated forests using unmanned aerial system structure from motion point clouds](https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=10356932785437169630)* (Creasy et al. 2021)

# Setup
  
```{r, include=FALSE, warning=F, message=F}
# knit options
knitr::opts_chunk$set(
  echo = TRUE
  , warning = FALSE
  , message = FALSE
  # , results='hide'
  , fig.width = 10
  , fig.height = 7
)
# Embed an interactive 3D plot with rgl
# https://bookdown.org/yihui/rmarkdown-cookbook/rgl-3d.html
library(rgl)
knitr::knit_hooks$set(webgl = hook_webgl)
```

## Load packages

Load all packages used in program.

*Note that the `TreeLS` package was removed from CRAN and must be installed from the development version on GitHub by uncommenting the relevant code section below.*

```{r pkg-load}
# bread-and-butter
library(tidyverse) # the tidyverse
library(viridis) # viridis colors
library(scales) # work with number and plot scales
library(latex2exp) # math formulas with latex

# spatial analysis
library(terra) # raster
library(sf) # simple features
library(sfarrow) # sf to Apache-Parquet files for working with large files
library(geometry) # mesh generation and surface tessellation
library(exactextractr) #summarizes raster values over polygonal areas ("zonal statistics")

# point cloud processing
library(lidR)
library(ForestTools) # for crown delineation but relies on depreciated `raster`
library(rlas)
## lidR::watershed requires EBImage::watershed 
  # install.packages("BiocManager")
  # BiocManager::install("EBImage")
  # library(BiocManager) # required for lidR::watershed
  library(EBImage) # required for lidR::watershed
## !! TreeLS package removed from CRAN...
  ## uncomment to install from github dev repo: https://github.com/tiagodc/TreeLS
  # library(pak)
  # pak::pkg_install("tiagodc/TreeLS")
  library(TreeLS) # removed from CRAN

# FIA data
## devtools::install_github('hunter-stanke/rFIA')
## library(rFIA) ## removed from CRAN

# modeling
library(randomForest)
library(Metrics)
library(RCSF) # for the cloth simulation filter (csf) to classify points

# parallel computing
library(ini) # Parse simple '.ini' configuration files to an structured list
library(parallel) # parallel
library(doParallel)
library(foreach) # facilitates parallelization by lapply'ing %dopar% on for loop

# visualization
library(mapview) # interactive html maps
library(randomcoloR)
library(plot3D)
library(rgl) # more 3d visualization

# others
library(dbscan)
library(deldir)
library(tools)
```

# User-Defined Parameters

Parameters to be set by the user

```{r parameter-set}
# !!!!!!!!!!!!!!!!!!!!!!! USER-DEFINED PARAMETERS !!!!!!!!!!!!!!!!!!!!!!! # 
###____________________###
### Set directory for outputs ###
###____________________###
# rootdir = "../data"
rootdir = "../data"
###_________________________###
### Set input las directory ###
###_________________________###
# !!!!!!!!!! ENSURE FILES ARE PROJECTED IN CRS THAT USES METRE AS MEASURMENT UNIT
input_las_dir = "../data/las_raw"
###__________________________________________________________###
### Set parameters for tiling, buffering, and tree detection ###
###__________________________________________________________###

### Set the resolution of the tile grid in metres
desired_tile_res = 50

### Set the desired buffer size in metres
desired_buffer_size = 10

###__________________________________________________________###
### Set parameters for the Canopy Height Model (CHM) ###
###__________________________________________________________###

### Set the maximum height for the canopy height model
max_height_threshold = 60
### Set the desired raster resolution in metres for the canopy height model
desired_chm_res = 1

### Set the maximum height for the stem-only canopy height model
max_stem_height_threshold = 60

### Set the window size for top down tree detection in metres
window_size = 3.5

### Set the minimum height (m) for individual tree detection in `lidR::locate_trees`
minimum_tree_height = 1.37

### Set the minimum crown size (m^2) to be retained after delineation
min_crown_size_m2 = 3

### Set the maximum dbh size (meters)
dbh_max_size_m = 1.5


# !!!!!!!!!!!!!!!!!!!!!!! USER-DEFINED PARAMETERS !!!!!!!!!!!!!!!!!!!!!!! #
```

# Data Load and Setup

```{r data-reduce, include=FALSE, eval=TRUE, fig.show='hide'}
# minimize the size of the las for testing
ctg_temp = lidR::readLAScatalog(input_las_dir)
roi_temp = ctg_temp@data$geometry %>% 
  sf::st_centroid() %>% 
  sf::st_buffer(dist = 100, endCapStyle = "SQUARE")
ggplot2::ggplot() +
  geom_sf(data = ctg_temp@data$geometry, alpha = 0, color = "gray") +
  geom_sf(data = roi_temp, alpha = 0, color = "black") +
  theme_void()
# clip the las and write
fnm_temp  = list.files(input_las_dir, pattern = ".*\\.(laz|las)$", full.names = T)[1]
lidR::clip_roi(ctg_temp, roi_temp) %>% 
  lidR::writeLAS(file = fnm_temp)
# re-read and map
new_ctg_temp = lidR::readLAScatalog(input_las_dir)
ggplot2::ggplot() +
  geom_sf(data = ctg_temp@data$geometry, alpha = 0, color = "gray", lwd = 2) +
  geom_sf(data = roi_temp, alpha = 0, color = "black", lwd = 3) +
  geom_sf(data = new_ctg_temp@data$geometry, alpha = 0, color = "white", lwd = 0.5) +
  theme_void()
# clean up
remove(list = ls()[grep("_temp",ls())])
gc()
```

## Configure File Structure

Use the user-defined directory to create output file structure. 

```{r file-config}
### Function to generate nested project directories
create_project_structure = function(rootdir,input_las_dir){
  ###______________________________________________###
  ### Set output las directory and sub directories ###
  ###______________________________________________###
  output_dir = file.path(rootdir, "02_processed_data")
  
  ### Set output directory for storing lasgrid object
  las_grid_dir = file.path(output_dir, "00_grid_dir")
  
  ### Set output directory for las tiles
  las_tile_dir = file.path(output_dir, "01_tiled_las")
  
  ### Set output directory for las ground tiles
  las_ground_tile_dir = file.path(output_dir, "02_tiled_ground_las")
  
  ### Set output directory for normalized tiles
  las_norm_tile_dir = file.path(output_dir, "03_tiled_normalized_las")
  
  ### Set output directory for the las stem files
  las_stem_dir = file.path(output_dir, "04_las_stem_dir")
  
  ### Set output directory for stem polygon tiles
  stem_poly_tile_dir = file.path(output_dir, "05_stem_polygon_dir")
  
  ### Set output directory for storing intermediate spatial files
  working_spatial_dir = file.path(output_dir, "06_working_spatial_dir")
  
  ### Set output directory for cropped tree files 
  las_tree_dir = file.path(output_dir, "07_las_tree_dir")
  
  ###___________________________________________________###
  ### Set output delivery directory amd sub directories ###
  ###___________________________________________________###
  delivery_dir = file.path(rootdir, "03_delivery")
  
  ### Set output delivery directory for stats files
  delivery_stats_dir = file.path(delivery_dir, "01_processing_stats")
  
  ### Set output delivery directory for spatial files
  delivery_spatial_dir = file.path(delivery_dir, "02_spatial_files")
  
  ### Set output delivery directory for point cloud files
  delivery_las_dir = file.path(delivery_dir, "03_las_files")
  
  ### Create the directories
  dir.create(las_grid_dir, showWarnings = FALSE)
  dir.create(output_dir, showWarnings = FALSE)
  dir.create(las_tile_dir, showWarnings = FALSE)
  dir.create(las_ground_tile_dir, showWarnings = FALSE)
  dir.create(las_norm_tile_dir, showWarnings = FALSE)
  dir.create(las_stem_dir, showWarnings = FALSE)
  dir.create(stem_poly_tile_dir, showWarnings = FALSE)
  dir.create(working_spatial_dir, showWarnings = FALSE)
  dir.create(las_tree_dir, showWarnings = FALSE)
  dir.create(delivery_dir, showWarnings = FALSE)
  dir.create(delivery_stats_dir, showWarnings = FALSE)
  dir.create(delivery_spatial_dir, showWarnings = FALSE)
  dir.create(delivery_las_dir, showWarnings = FALSE)
  
  ###______________________________###
  ### Set names of the directories ###
  ###______________________________###
  
  names(rootdir) = "rootdir"
  names(input_las_dir) = "input_las_dir"
  names(output_dir) = "output_dir"
  names(las_grid_dir) = "las_grid_dir"
  names(las_tile_dir) = "las_tile_dir"
  names(las_ground_tile_dir) = "las_ground_tile_dir"
  names(las_norm_tile_dir) = "las_norm_tile_dir"
  names(las_stem_dir) = "las_stem_dir"
  names(stem_poly_tile_dir) = "stem_poly_tile_dir"
  names(working_spatial_dir) = "working_spatial_dir"
  names(las_tree_dir) = "las_tree_dir"
  names(delivery_dir) = "delivery_dir"
  names(delivery_stats_dir) = "delivery_stats_dir"
  names(delivery_spatial_dir) = "delivery_spatial_dir"
  names(delivery_las_dir) = "delivery_las_dir"
  
  ###______________________________###
  ### Append to output config list ###
  ###______________________________###
  
  config = cbind(rootdir, input_las_dir, output_dir, las_grid_dir, las_tile_dir, las_ground_tile_dir,
                 las_norm_tile_dir, las_stem_dir, stem_poly_tile_dir, working_spatial_dir,
                 las_tree_dir,delivery_dir, delivery_stats_dir, delivery_spatial_dir, delivery_las_dir)
  
  config = as.data.frame(config)
  #config
  
  ### Return config 
  return(config)
  
}
config = create_project_structure(rootdir, input_las_dir)
```

## Read Point Cloud Data

Function to read in available `las` or `laz` data.

```{r read-las, results='asis', message=TRUE}
### Function to read in available las data within input directory
read_las_as_ctg = function(config){
  ### Get the input directory read in 
  ctg = lidR::readLAScatalog(config$input_las_dir)
  # print(ctg)
  # print(st_crs(ctg))
  return(ctg)
}
### Read in the las files, check the number of points and CRS
las_ctg = read_las_as_ctg(config)
las_ctg
if(
  lidR::st_crs(las_ctg, parameters = TRUE)$units_gdal != "metre"
){ stop("las file not projected in coordinate system that uses metre as measurement unit")}
```

Map point cloud extent

```{r map-las}
# map of point cloud extent
# mapview
mapview::mapviewOptions(
  homebutton = FALSE
  , basemaps = c("OpenStreetMap","Esri.WorldImagery")
)
mapview::mapview(las_ctg@data$geometry, color = "black", col.regions = "blue", lwd = 3, alpha.regions = 0.3, legend = F, label = F)
```

## Make Spatial Grid Over Extent{#make_grid}

Make a raster grid covering the point cloud extent with the desired tile resolution in cm.

<span style="color: red;">This grid is used for ??? 1. make smaller laz files to loop processing over (see [`new_tile_las_to_grid_foreach` function](#tile_las_grid))</span>

```{r make-grid-fn}
### Function to check input las and extent of desired tile resolution
generate_grid_over_extent = function(las_ctg, desired_tile_res){
  
  ### Pull the las extent geometry
  las_ctg_geom = sf::st_as_sf(las_ctg@data$geometry)
  
  ### Make a grid with the desired tile size
    # cellsize units determined by projection
  grid = sf::st_make_grid(las_ctg_geom, cellsize = desired_tile_res)
  grid = sf::st_as_sf(grid)
  
  ### Create grid ID 
  grid_id = rep(1:nrow(grid))
  grid = cbind(grid, grid_id)
  
  message("Output grid has ", nrow(grid), " tiles ...")
  
  return(grid)
}
```

Call the function to make the grid and save to disk as `parquet` file which allows for fast read/write. A key goal of the `sfarrow` package is to support inter-operability of spatial data in files between R and Python through the use of standardized metadata.

<span style="color: red;">*George W. notes: this buffer is buffering each tile instead of buffering the extent and then creating the grid...which is it supposed to be for processing?*</span>

```{r make-grid}
### Generate the grid
las_grid = generate_grid_over_extent(las_ctg, desired_tile_res)
# this buffer is buffering each cell instead of buffering the extent and then creating the grid
las_grid_buff = sf::st_buffer(las_grid, desired_buffer_size)
###____________________________###
### Write the grid to the disk ###
###____________________________###
sfarrow::st_write_parquet(
  las_grid
  , dsn = paste0(
      config$las_grid_dir
      , "/"
      , "project_grid.parquet"
    )
)
```

Map grid and point cloud extent 

```{r map-grid}
mapview::mapview(
    las_ctg@data$geometry
    , color = "black"
    , col.regions = "blue"
    , lwd = 3, alpha.regions = 0.3, legend = F, label = F
  ) +
  mapview::mapview(las_grid_buff, color = "gray55", alpha.regions = 0, lwd = 2, legend = F, label = F, hide = F) +
  mapview::mapview(las_grid, color = "gray22", alpha.regions = 0, lwd = 1, legend = F, label = F, hide = F)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

## Spatial Index Point Cloud Function{#make_lax}

Spatial index the point cloud to enable more efficient point cloud querying. From [The `lidR` Package Book](https://r-lidar.github.io/lidRbook/spatial-indexing.html):

*Spatial indexing is a key feature for performing spatial queries over a large point cloud. Any search for points of interest in the absence of indexing would require a “sequential scan” of every point - this could take a lot of time. In brief, spatial indexing organizes data into a search structure that can be quickly traversed to find specific records. Some algorithms would take unreasonable amounts of time to complete without spatial indexing.*

```{r create-lax-fn}
### Function to generate .lax index files for input directory path
create_lax_for_tiles = function(desired_las_dir){
  ## desired_las_dir = config$input_las_dir
  ###__________________________________________###
  ### Create a lax index file for the las file ###
  ###__________________________________________###
  message(paste0("Initializing .lax indexing for ", desired_las_dir, " ... "))
  las_list = list.files(desired_las_dir, pattern = ".las")
  laz_list = list.files(desired_las_dir, pattern = ".laz")
  lidar_list = append(las_list, laz_list)
  # lidar_list
  
  message("Indexing ", length(lidar_list), " las files ... ")
  
  start_time = Sys.time()
  # configure parallel
  cores = parallel::detectCores()
  cluster = parallel::makeCluster(cores)
  # register the parallel backend with the `foreach` package
  doParallel::registerDoParallel(cluster)
  # pass to foreach to process each lidar file in parallel
  foreach::foreach(i = 1:length(lidar_list)) %dopar% {
    
    ### Get the desired file
    des_file = lidar_list[i]
    # des_file
    
    ### Compile the .lax file name
    des_file_lax = tools::file_path_sans_ext(des_file)
    des_file_lax = paste0(des_file_lax, ".lax")
    des_file_lax_path = paste0(desired_las_dir, "/", des_file_lax)
    # des_file_lax_path
    
    ### See if the .lax version exists in the input directory
    does_file_exsist = file.exists(des_file_lax_path)
    # does_file_exsist
    
    ### If file exsists, do nothing
    if(does_file_exsist == TRUE){return(NULL)}
    
    ### If file doesnt exsist, create a .lax index
    if(does_file_exsist == FALSE){
      
      ### Append the directory path to the las file
      path = paste0(desired_las_dir, "/", des_file)
      
      ### Write index
      rlas::writelax(path)
      
    }
    
  }
  parallel::stopCluster(cluster)
  end_time = Sys.time()
  total_time = difftime(end_time, start_time, units = c("mins"))
  message("Total lax index time took ", total_time, " minutes ... ")
  
}
```

### Apply Spatial Index to Raw Point Cloud

Create the spatial index `lax` file for the raw input point cloud.

```{r create-lax-raw, results='hide'}
# call the function
create_lax_for_tiles(config$input_las_dir)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

## Tile Raw Point Cloud to Grid{#tile_las_grid}

This function writes individual point cloud `laz` files for each [grid tile](#make_grid) to the disk in the "`r config$las_tile_dir`" directory. Each grid tile is buffered by the user-defined buffer and the raw point cloud is cropped to that extent. The purpose is to...??? (reduce processing time)

<span style="color: red;">George W. notes: is there potential for individual trees to either be i) double-counted if crown spans multiple grid tiles; or ii) excluded when recombining tiles and removing duplicates? Not sure what the recombine process looks like yet.</span>

```{r tile-las-fn}
### New function to tile the raw point cloud to the desired grid - with buffers 
new_tile_las_to_grid_foreach = function(
  config
  , desired_buffer_size
  , my_las_grid = las_grid # generate_grid_over_extent(las_ctg, desired_tile_res)
  , my_las_ctg = las_ctg # lidR::readLAScatalog(config$input_las_dir)
){
  # define files
  las_grid = my_las_grid
  las_ctg = my_las_ctg
  # start message
  message(" --- Starting grid tiling algorithim --- ")
  master_start = Sys.time()
  # ###_____________________________###
  # ### Read in the las grid object ###
  # ###_____________________________###
  #   ## !!!!!!! the grid is already in memory, no need to re-read
  #   message("Reading in project grid ... ")
  #   ## read parquet grid created with generate_grid_over_extent function above
  #   grid_fpth_temp = paste0(
  #     config$las_grid_dir
  #     , "/"
  #     , "project_grid.parquet"
  #   )
  #   las_grid = sfarrow::st_read_parquet(grid_fpth_temp)
  # ###_____________________________###
  # ### Read in the lascatalog  ###
  # ###_____________________________###
  #   ## !!!!!!! the lascatalog is already in memory, no need to re-read
  #   message("Reading in the las as a lascatalog for indexing ... ")
  #   las_ctg = lidR::readLAScatalog(config$input_las_dir)

  ###____________________________________________###
  ### Loop through grid tiles and tile the input las object ###
  ###____________________________________________###
    start_time = Sys.time()
    ## !!!!!! TURNED OFF PARALLEL B/C IT KILLS STUFF
    # # set up parallel processing
    # cores = parallel::detectCores()
    # message("Registering parallel session on ",  cores-2, " cores ... ")
    # cluster = parallel::makeCluster(cores-2)
    # doParallel::registerDoParallel(cluster)
    ## !!!!!! TURNED OFF PARALLEL B/C IT KILLS STUFF
    # message("Starting NON-parallel ;D grid tiling at ", start_time)
    message("Creating tiles for ", nrow(las_grid), " grids ... ")
    ## loop over grid tiles but NOT in parallel ftw
    for(i in 1:nrow(las_grid)) {
    # for(i in 1:4) {
      # message("Creating laz for grid number ", i, " ... ")
    ## !!!!!! TURNED OFF PARALLEL B/C IT KILLS STUFF
    # loop over grid tiles but in parallel ftw
    # foreach::foreach(
    #   i=1:nrow(las_grid)
    #   , .packages = c("lidR", "sf")
    #   , .inorder = FALSE
    #   , .errorhandling = "remove"
    # ) %dopar% {
    ## !!!!!! TURNED OFF PARALLEL B/C IT KILLS STUFF
      
      ### Get the desired grid
      des_grid_cell = las_grid[i,]
      # des_grid_cell
      
      ### Does file exist
      file_to_generate = paste0(config$las_tile_dir, "/", i, ".laz")
      does_file_exist = file.exists(file_to_generate)
      # does_file_exist
      
      ### If file has been generated already, skip
      if(does_file_exist == TRUE){
        message("laz for grid number ", i, " already exists guy ... ")
      }
      
      ### If file has not been generated already, try to generate
      if(does_file_exist == FALSE){
        
        ### Buffer the grid cell to the desired buffer size
        des_grid_cell_buff = sf::st_buffer(des_grid_cell, desired_buffer_size)
        
        ### Crop the las file from the catalog for the grid cell extent  
        las_clipped = suppressWarnings(lidR::clip_roi(las_ctg, des_grid_cell_buff))
        #st_crs(las) = st_crs(las_grid)
        
        ### Check if the point cloud is empty
        is_cloud_empty = suppressWarnings(lidR::is.empty(las_clipped))
        # is_cloud_empty
        
        ### If is_cloud_empty == TRUE, return NULL
        if(is_cloud_empty == TRUE){
          message("laz for grid number ", i, " is empty so i skipped it ... ")
        }
        
        ### If is_cloud_empty = FALSE, write to disk
        if(is_cloud_empty == FALSE){
          
          ### Write the cropped las to the disk
          out_name = paste0(
            config$las_tile_dir
            , "/"
            , des_grid_cell$grid_id
            , ".laz"
          )
          suppressWarnings(lidR::writeLAS(las_clipped, out_name))
          ## return(NULL) # this kills it or something
          # message("Hey i wrote a laz for grid number ", i, " ... ")
        } # is_cloud_empty
      } # does_file_exist
    } # foreach grid
    ## !!!!!! TURNED OFF PARALLEL B/C IT KILLS STUFF
    # parallel::stopCluster(cluster)
    ## !!!!!! TURNED OFF PARALLEL B/C IT KILLS STUFF
    end_time = Sys.time()
    total_time = difftime(end_time, start_time, units = c("mins"))
    message("Total grid tiling time took ", total_time, " minutes ... ")
    
  ### Get some stats for the tiling run
  tiled_ctg = lidR::readLAScatalog(config$las_tile_dir)
  tiled_ctg_geom = tiled_ctg$geometry
  tiled_ctg_geom = sf::st_as_sf(tiled_ctg_geom)
  las_area_m2 = sum(sf::st_area(tiled_ctg_geom))
  las_area_acres = las_area_m2/4047
  processing_time_mins = total_time
  number_starting_grids = nrow(las_grid)
  number_ending_grids = nrow(tiled_ctg_geom)
  
  ### Combine the output stats dataframe and write to the disk
  stats_output = data.frame(
    number_starting_grids, number_ending_grids, las_area_m2
    , las_area_acres, processing_time_mins
  )
  write.csv(
    stats_output
    , file = paste0(config$delivery_stats_dir,"/","01_grid_tiling_stats.csv")
  )
  
  ### Get a list of tiles that processed
  processed_tile_list = list.files(config$las_tile_dir)
  message(length(processed_tile_list), " files were generated ... ")
  message(length(processed_tile_list)/nrow(las_grid) *100, " percent of tile grid occupied with spatial points ... ")
  
  return(tiled_ctg_geom)
  
}
```

Call the function to make the tiled `laz` files and write to disk. Also, call the function to create the `lax` [spatial indexed](#make_lax) file for each tiled grid file.

```{r tile-las, message=FALSE, warning=FALSE, results='hide', fig.show='hide'}
tiled_grid = new_tile_las_to_grid_foreach(
  config = config
  , desired_buffer_size = desired_buffer_size
  , my_las_grid = las_grid
  , my_las_ctg = las_ctg
)
create_lax_for_tiles(config$las_tile_dir)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

Map the tiled grid extent and the raw point cloud extent

```{r map-tiled-grid}
mapview::mapview(
    las_ctg@data$geometry
    , color = "black"
    , col.regions = "blue"
    , lwd = 3, alpha.regions = 0.3, legend = F, label = F
  ) +
  mapview::mapview(tiled_grid, color = "gray55", alpha.regions = 0, lwd = 2, legend = F, label = F, hide = F)
```

# Classify Points{#classify_points}

Classify the point cloud points as ground or non-ground. Use this classification to height normalize the [tiled `laz` files](#tile_las_grid).

Points are classified using the `lidR::classify` function with the option `algorithm = csf(rigidness = 1, sloop_smooth = TRUE)` . The `csf` ground classification algorithm implements an algorithm for segmentation of ground points based on a "Cloth Simulation Filter" (CSF). This method is a strict implementation of the CSF algorithm made by [Zhang et al. (2016)](https://scholar.google.com/scholar?cluster=12762834065727315668&hl=en&as_sdt=0,5) that relies on the authors’ original source code written and exposed to R via the the `RCSF` package. The `rigidness` of the cloth set to the default 1 stands for very soft (to fit rugged terrain), 2 stands for medium, and 3 stands for hard cloth (for flat terrain). When steep slopes exist, the `sloop_smooth` parameter set to `TRUE` reduces errors during post-processing.

The points are normalized using the `lidR::normalize_height` function with the option `algorithm = knnidw()` . By default the terrain is computed by using ground points (class 2) and water points (class 9) which requires the points to be classified before normalizing the height. The `knnidw` algorithm implements an algorithm for spatial interpolation using a k-nearest neighbour (KNN) approach with an inverse-distance weighting (IDW). An alternative height normalization process uses a separate digital terrain model (DTM) raster via the `dtm` option. When a DTM raster is provided, then the DTM is used in place of ground points. This is different than providing a DTM in algorithm. If `algorithm = dtm` the DTM is subtracted naively. If `algorithm = tin()` and `dtm = raster` the ground points are not used and the DTM is interpolated as if it were made of regularly-spaced ground points.

After height normalizing the points, non-ground points that are below the ground surface are removed using `lidR::filter_poi(las, Z > -0.05)` and high-elevation outlier points are removed using `lidR::filter_poi(las, Z < quantile(las@data$Z, 0.99999))` .

An alternative method to detect and remove outliers is available via the `lidR::classify_noise` function. For example: 

```{r ex-outlier, eval=FALSE, include=TRUE}
# Using IVF
las <- lidR::classify_noise(las, ivf(res=5, n=2))
#plot(las, color = "Classification")

# Remove outliers using filter_poi()
las_denoise <- lidR::filter_poi(las, Classification != LASNOISE)
```

, where `ivf` implements an algorithm for outliers (noise) segmentation based on isolated voxels filter (IVF). The algorithm finds points that have only a few other points in their surrounding 3 x 3 x 3 = 27 voxels.

<span style="color: red;">George W. notes: the point classification and height normalization procedures are using only data within the bounds of each individual tile (+buffer). How does this impact: i) classification of ground (e.g. in low point density tiles or tiles with limited canopy penetration) and the resulting normalization; ii) the detection of outlier points based on normalized height within the tile versus across the entire point cloud extent? Also, should outliers (noise) be detected and removed prior to applying the ground classification (currently is applied after at the individual grid tile level)?</span>

```{r classify-points-fn}
### Function to classify ground and height normalize las tiles
classify_ground_normalize = function(
  config = config
  , my_las_grid = las_grid # generate_grid_over_extent(las_ctg, desired_tile_res)
  , my_las_ctg = las_ctg # lidR::readLAScatalog(config$input_las_dir)
  , want_to_classify_ground = T
){
  # define files passed to function
  las_grid = my_las_grid
  las_ctg = my_las_ctg
  
  ###_______________________###
  ### Configure directories ###
  ###_______________________###
  
  message(" --- Initializing ground classification and normalization algorithm --- ")
  master_start = Sys.time()
  
  ###_____________________________###
  ### Read in the las grid object ###
  ###_____________________________###
  ## !!!! THIS IS ALREADY IN MEMORY, NO NEED TO RE-READ
  # message("Reading in project grid ... ")
  # las_grid = sfarrow::st_read_parquet(paste0(
  #   config$las_grid_dir
  #   , "/"
  #   , "project_grid.parquet"
  # ))
  # 
  # message("Reading in the las as a lascatalog for indexing ... ")
  # las_ctg = lidR::readALSLAScatalog(config$input_las_dir)
  
  ###________________________________________###
  ### Next, classify ground across the tiles ###
  ###________________________________________###
  
  ### Get a list of tiled files to ground classify
  las_list = list.files(config$las_tile_dir, pattern = ".las")
  laz_list = list.files(config$las_tile_dir, pattern = ".laz")
  lidar_list = append(las_list, laz_list)
  message("Classifying ", length(lidar_list), " ground and height normalizing tiles in parallel ... ")
  # lidar_list
  
  ###______________________________________________________________________________________###
  ### In parallel, classify ground, and height normalize across the tiles and rewrite them ###
  ###______________________________________________________________________________________###
  
  start_time = Sys.time()
  ## !!!!!! TURNED OFF PARALLEL B/C IT KILLS STUFF
  # set up parallel processing
  # cores = parallel::detectCores()
  # message("Registering parallel session on ", cores-1, " cores ... ")
  # cluster = parallel::makeCluster(cores-1)
  # doParallel::registerDoParallel(cluster)
  ## !!!!!! TURNED OFF PARALLEL B/C IT KILLS STUFF
  message("Starting NON-parallel classification/normalization ... ")
  # loop over each tiled las file to classify and normalize
  for(i in 1:length(lidar_list)) {
  # for(i in 1:4) {
  ## !!!!!! TURNED OFF PARALLEL B/C IT KILLS STUFF  
  # foreach(
  #   # i = 1:length(lidar_list)
  #   , .packages = c("lidR", "sf")
  #   , .inorder = FALSE
  #   , .errorhandling = "remove"
  # ) %dopar% {
  ## !!!!!! TURNED OFF PARALLEL B/C IT KILLS STUFF
    
    ### Get the desired lidar tile
    des_tile_name = lidar_list[i]
    # des_tile_name
    
    ### Has the file been generated already?
    des_tile_to_check = paste0(config$las_norm_tile_dir, "/", des_tile_name)
    does_file_exist = file.exists(des_tile_to_check)
    # does_file_exist
    
    ### If file exists, skip
    if(does_file_exist == TRUE){
      message("normalized tile ", des_tile_to_check, " exists so skipped it ... ")
    }
    
    ### If file does not exsist, classify and height normalize
    if(does_file_exist == FALSE){
      
      ### Get the matching grid polygon 
      las_grid_id = tools::file_path_sans_ext(des_tile_name)
      matching_grid_cell = las_grid[las_grid$grid_id == las_grid_id,]
      # matching_grid_cell
      
      ### Read in the lidar tile
      las_tile = lidR::readALSLAS(paste0(
        config$las_tile_dir
        , "/"
        , des_tile_name
      ))
      #st_crs(las_tile) = st_crs(las_grid)
      
      ### Drop duplicated points
      las_tile = lidR::filter_duplicates(las_tile)
      
      ### Set threads to 2 for speed up in height normalization
      lidR::set_lidr_threads(1)
      
      ### Classify ground points
      if(want_to_classify_ground == TRUE){
        las_tile = lidR::classify_ground(
          las_tile
          , algorithm = csf(rigidness = 1, sloop_smooth = TRUE)
        )
      }
      
      ### Pull out the ground points
      ground = lidR::filter_poi(las_tile, Classification == 2)
      
      ### Check if ground is empty, if not, write to disk
      ground_is_empty = lidR::is.empty(ground)
      # ground_is_empty
      
      if(ground_is_empty == FALSE){
        lidR::writeLAS(
          ground
          , file = paste0(
            config$las_ground_tile_dir
            , "/"
            , des_tile_name
          )
        )
      }
      
      ### Height normalize the file
      las_tile = lidR::normalize_height(las_tile, algorithm = knnidw())
      
      ### Remove points below 0.05
      las_tile = lidR::filter_poi(las_tile, Z > -0.05)
      
      ### Remove high outlier points
      height_filter = quantile(las_tile@data$Z, 0.99999)
      las_tile = lidR::filter_poi(las_tile, Z < height_filter)
      
      ### Set crs
      #desired_crs = sf::st_crs(las_grid)
      #lidR::st_crs(las_tile) = desired_crs
      #las_tile
      
      ### Crop the las to the original grid polygon
      las_tile = lidR::clip_roi(las_tile, matching_grid_cell)
      
      ### Is las null?
      check = is.null(las_tile)
      
      ### If las is null, return NULL
      if(check == TRUE){
        message("normalized laz for grid number ", i, " is null ... ")
      }
      
      ### Is the las file empty
      is_las_empty = lidR::is.empty(las_tile)
      # is_las_empty
      
      ### If las is empty, return Null
      if(is_las_empty == TRUE){
        message("normalized laz for grid number ", i, " is empty (void of pts) ... ")
      }
      
      ### If las isnt empty, write the las to the disk
      if(is_las_empty == FALSE){
        
        ### Overwrite the existing file
        lidR::writeLAS(
          las_tile
          , file = paste0(
            config$las_norm_tile_dir
            , "/"
            , des_tile_name
          )
        )
        message("normalized laz for grid number ", i, " completed successfully ... ")
        
      }
      
    }
    
  }
  ## !!!!!! TURNED OFF PARALLEL B/C IT KILLS STUFF
  # parallel::stopCluster(cluster)
  ## !!!!!! TURNED OFF PARALLEL B/C IT KILLS STUFF
  end_time = Sys.time()
  total_time = difftime(end_time, start_time, units = c("mins"))
  message("Total ground classification and height normalization complete in ", total_time,  " minutes ... ")
  
  ###________________________________________###
  ### Get a catalog of the normalized points ###
  ###________________________________________###
  
  message("Reading in the normalized las file as a catalog ... ")
  ctg = lidR::readALSLAScatalog(config$las_norm_tile_dir)
  ctg_geom = ctg$geometry
  num_points_list = ctg$Number.of.point.records
  num_points_list = unlist(num_points_list)
  num_points_list = as.data.frame(num_points_list)
  number_points = sum(num_points_list$num_points_list)
  # number_points
  
  ### Get the area of the dataset ina acres
  catalog_area = sf::st_union(ctg@data$geometry)
  catalog_area = sf::st_area(catalog_area)
  catalog_area = as.numeric(catalog_area)
  las_area_m2 = catalog_area
  las_area_acres = catalog_area/4047
  # las_area_acres
  
  ### Get a list of processed files
  normalized_file_list = list.files(config$las_norm_tile_dir, pattern = ".laz")
  message(length(normalized_file_list), " lidar files height normalized ... ")
  difference = length(lidar_list) - length(normalized_file_list)
  message(difference, " files failed height normalization ...")
  
  ###_______________________________###
  ### Get the total processing time ###
  ###_______________________________###
  
  master_end = Sys.time()
  total_master_time = difftime(master_end, master_start, units = c("mins"))
  
  ###____________________________________________###
  ### Write some stats to the delivery directory ###
  ###____________________________________________###
  processing_time_mins = total_master_time
  stats_output = data.frame(number_points, las_area_m2, las_area_acres, processing_time_mins)
  
  write.csv(stats_output, file = paste0(
    config$delivery_stats_dir
    , "/" 
    , "02_point_cloud_classification_normalization_stats.csv"
  ))
  message(" --- Total ground classification and height normalization took ", total_master_time, " minutes --- ")
  
  return(ctg_geom)
  
}
```

Call the function to classify ground/non-ground points and height normalize the tiled point clouds and write to disk. Also, call the function to create the `lax` [spatial indexed](#make_lax) file for each normalized tile grid.

```{r classify-points, message=FALSE, warning=FALSE, results='hide'}
height_norm_grid = classify_ground_normalize(
  config = config
  , my_las_grid = las_grid # generate_grid_over_extent(las_ctg, desired_tile_res)
  , my_las_ctg = las_ctg # lidR::readLAScatalog(config$input_las_dir)
  , want_to_classify_ground = T
)
create_lax_for_tiles(config$las_ground_tile_dir)
create_lax_for_tiles(config$las_norm_tile_dir)
```

Map the classified and normalized grid tiles

```{r map-classify-points}
mapview::mapview(
    las_ctg@data$geometry
    , color = "black"
    , col.regions = "blue"
    , lwd = 3, alpha.regions = 0.3, legend = F, label = F
  ) +
  mapview::mapview(height_norm_grid, color = "gray55", alpha.regions = 0, lwd = 2, legend = F, label = F, hide = F)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
# remove this grid thing
remove(height_norm_grid)
# clean up
remove(list = ls()[grep("_temp",ls())])
gc()
```

# Create DTM{#create_dtm}

This section uses the point cloud grid tiles with only points classified as "ground" (created in [this section](#classify_points)) to create a DTM raster. 

The process loops over each ground point cloud grid tile and creates a DTM raster of user-specified resolution. The specific function used for each tile is:

`lidR::rasterize_canopy(las_ground_tile, res = 3, algorithm = p2r(), pkg = "terra")` 

, where the `algorithm = p2r()` option implements an algorithm for digital surface model computation based on a points-to-raster method: for each pixel of the output raster the function attributes the height of the highest point found. The subcircle tweak replaces each point with 8 points around the original one. This allows for virtual ’emulation’ of the fact that a lidar point is not a point as such, but more realistically a disc. This tweak densifies the point cloud and the resulting canopy model is smoother and contains fewer "pits" and empty pixels. The `pkg = "terra"` results in a raster that is compatible with the `terra` package.

It is worth noting that the `lidR` [package](https://cran.r-project.org/web/packages/lidR/lidR.pdf) includes a `rasterize_terrain` function which interpolates the ground points (in a classified point cloud *that has not been normalized*) and creates a rasterized digital terrain model. The algorithm uses the points classified as "ground" and "water" (Classification = 2 and 9, respectively) to compute the interpolation. How well the edges of the dataset are interpolated depends on the interpolation method used. A buffer around the region of interest is always recommended to avoid edge effects. This function can be implemented via:

```{r ex-rasterize-terrain, include=TRUE, eval=FALSE}
dtm1 = rasterize_terrain(las, algorithm = knnidw(k = 6L, p = 2))
dtm2 = rasterize_terrain(las, algorithm = tin())
dtm3 = rasterize_terrain(las, algorithm = kriging(k = 10L))
# plot results
plot(dtm1, col = gray(0:25/25))
plot(dtm2, col = gray(0:25/25))
plot(dtm3, col = gray(0:25/25))
plot_dtm3d(dtm1)
plot_dtm3d(dtm2)
plot_dtm3d(dtm3)
```

<span style="color: red;">George W. notes: none of the interpolation algorithms available in `lidR::rasterize_terrain` use single-point methods to create the DTM. As written, this program uses `lidR::rasterize_canopy` with the `p2r` algorithm set to attribute the height of the highest point found to the value of the raster tile. This could result in i) empty cells; and/or ii) a less smooth DTM which is influenced by artifact points (especially since the current outlier removal is applied only to the non-ground points *after* the classification algorithm is applied). Furthermore, as a  DTM is created for each tile separately, there is potential for edge effects to be amplified across the study extent. Calculating the DTM for each tile separately excludes valid data which would be otherwise available to the algorithm if processed altogether. A potential solution is to continue processing by grid tiles with a buffer that overlaps with neighboring tiles, use a multi-point interpolation algorithm on each buffered tile, and then combine the grid tile rasters via `terra::mosaic` where values in overlapping cells are averaged. Or, process as a single point cloud over the entire study extent.</span>

```{r create-dtm-fn}
# GW added
# create funtion to read las, rasterize, and return data frame
las2dtm2df <- function(las_path_name, des_dtm_res = 3) {
  ### Read in the file
  las_ground_tile = lidR::readLAS(las_path_name, select = "xyzc")
  
  ### Create a DEM from the file
  dtm_tile = lidR::rasterize_canopy(
    las_ground_tile
    , res = des_dtm_res
    , algorithm = p2r()
    , pkg = "terra"
  )
  
  ### Get the DEM points
  dtm_points = as.data.frame(dtm_tile, xy = T) %>% 
    dplyr::rename_with(toupper)
  
  ### Return the points to the function 
  return(dtm_points)
}
## map files over the function
# list.files(config$las_ground_tile_dir, pattern = ".*\\.(laz|las)$", full.names = T) %>%
#   .[2:3] %>%
#   purrr::map(las2dtm2df) %>%
#   dplyr::bind_rows() %>%
#   str()
  

### Function to get DTM from ground classified tiles
rasterize_tiles_to_dtm = function(
  config
  , my_des_dtm_res = 3 #in meters
  , calculate_extent = TRUE
  , my_las_grid = las_grid # generate_grid_over_extent(las_ctg, desired_tile_res)
  , my_las_ctg = las_ctg # lidR::readLAScatalog(config$input_las_dir)
){
  # define files
  las_grid = my_las_grid
  las_ctg = my_las_ctg
  
  message(" --- Initializing digitial elevation model rasterization --- ")
  master_start = Sys.time()
  
  # ###_____________________________###
  # ### Read in the las grid object ###
  # ###_____________________________###
  # ## !!!!!!! the grid is already in memory, no need to re-read 
  # message("Reading in project grid ... ")
  # las_grid = sfarrow::st_read_parquet(paste0(
  #   config$las_grid_dir
  #   , "/"
  #   , "project_grid.parquet")
  # )
  # 
  # message("Reading in the las as a lascatalog for indexing ... ")
  # las_ctg = lidR::readLAScatalog(config$input_las_dir)
  # las_ctg
  
  ###_______________________________________________________________________________###
  ### Get a list of classified ground normalized tiles to generate DTM raster files ###
  ###_______________________________________________________________________________###
  ### Loop through and generate DTM data.frame for each tile and then bind_rows
  start_time = Sys.time()
  # file list
  tile_list = list.files(config$las_ground_tile_dir, pattern = ".*\\.(laz|las)$", full.names = T)
  # map las2dtm2df function
  merged_dtm_points = tile_list %>%
    purrr::map(las2dtm2df, des_dtm_res = my_des_dtm_res) %>%
    # .[2:3] %>%
    dplyr::bind_rows()
  
  ###_____________________________________###
  ### Make a las file from the CHM points ###
  ###_____________________________________###
  
  message("Generating the master LiDAR file ... ")
  las = lidR::LAS(merged_dtm_points)
  sf::st_crs(las) = sf::st_crs(las_grid)
  # las
  
  ### Write cleaned las to the disk
  message("Writing the master lidar file to the disk ... ")
  lidR::writeLAS(las, file = paste0(
    config$delivery_las_dir
    , "/"
    , "master_dem_point_cloud.laz"
  ))
  
  las_area_m2 = lidR::area(las)
  las_area_acres = las_area_m2/4047
  message("Total merged DEM area of ", las_area_acres, " acres .... ")
  
  ###____________________________________###
  ### Generate a CHM from the CHM points ###
  ###____________________________________###
  
  message("Generating the master DEM file ... ")
  master_dem = lidR::rasterize_canopy(las, res = my_des_dtm_res, algorithm = p2r())
  # master_dem
  
  ###_____________________________________###
  ### Write the master raster to the disk ###
  ###_____________________________________###
  
  message("Writing the master DEM file to the disk ... ")
  outname = paste0(
    config$delivery_spatial_dir
    , "/"
    , "master_dem_raster_", my_des_dtm_res, "m.tif"
  )
  terra::writeRaster(master_dem, outname, overwrite = TRUE)
  
  ###_______________________________________###
  ### Get a polygon of the full file extent ###
  ###_______________________________________###
  
  if(calculate_extent == TRUE){
    
    message("Getting the extent of the DEM file ... ")
    extent_raster = terra::clamp(master_dem, 1, 1, 1)
    extent_poly = terra::as.polygons(extent_raster)
    extent_poly = terra::simplifyGeom(extent_poly)
    extent_poly = terra::fillHoles(extent_poly)
    extent_poly = sf::st_as_sf(extent_poly)
    extent_poly = st_union(extent_poly)
    extent_poly = st_as_sf(extent_poly)
    # extent_poly
    
    ### Write the poly to the disk
    #sf::st_write(extent_poly, dsn = "chm_extent_kml.kml", delete_dsn = TRUE, quiet = TRUE)
    sf::st_write(
      extent_poly
      , dsn = paste0(
        config$working_spatial_dir
        , "/dem_extent_geopackage.gpkg"
      )
      , delete_dsn = TRUE
      , quiet = TRUE
    )
    
  }
  
  ###____________________###
  ### Get the total time ###
  ###____________________###
  
  end_time = Sys.time()
  total_time = difftime(end_time, start_time, units = c("mins"))
  message(" --- Total DEM rasterization took ", total_time, " minutes --- ")
  
}

```

Call the function to create the DTM

```{r create-dtm, results='hide', fig.show='hide', message=FALSE}
rasterize_tiles_to_dtm(
  config = config
  , my_des_dtm_res = 3 #in meters
  , calculate_extent = F
  , my_las_grid = las_grid # generate_grid_over_extent(las_ctg, desired_tile_res)
  , my_las_ctg = las_ctg # lidR::readLAScatalog(config$input_las_dir)
)
```

Map the DTM

```{r map-dtm}
terra::rast(paste0(
  config$delivery_spatial_dir
  , "/master_dem_raster_3m.tif"
)) %>%
  stars::st_as_stars() %>% 
  mapview::mapview(
    layer.name = "elev.(m)"
    , alpha.regions = 0.6
  )
# # uncomment for ggplot
#   as.data.frame(xy=T) %>% 
#   dplyr::rename_with(tolower) %>% 
#   dplyr::rename(f=3) %>% 
#   ggplot(mapping = aes(x=x,y=y,fill=f)) +
#     geom_tile() +
#     scale_fill_viridis_c(na.value = "black") +
#     labs(fill = "elevation (m)") +
#     theme_void()
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

# Create Canopy Height Model{#create_chm}

This section uses the height normalized point cloud grid tiles (created in [this section](#classify_points)) to create a CHM raster.

The process loops over each normalized point cloud grid tile and creates a Canopy Height Model (CHM) raster of user-specified resolution. The specific function used for each tile is:

`lidR::rasterize_canopy(las_norm_tile, res = 1, algorithm = p2r(), pkg = "terra")` 

, where the `algorithm = p2r()` option implements an algorithm for digital surface model computation based on a points-to-raster method: for each pixel of the output raster the function attributes the height of the highest point found. The subcircle tweak replaces each point with 8 points around the original one. This allows for virtual ’emulation’ of the fact that a lidar point is not a point as such, but more realistically a disc. This tweak densifies the point cloud and the resulting canopy model is smoother and contains fewer "pits" and empty pixels. The `pkg = "terra"` results in a raster that is compatible with the `terra` package.

<span style="color: red;">George W. notes: The [DTM process](#create_dtm) and CHM process both use `lidR::rasterize_canopy` with the `p2r` algorithm to attribute the height of the raster to the highest point found to the value of the raster tile. The current program: 

1. Uses `lidR::rasterize_canopy` with the `p2r` algorithm to create a raster separately for each tile
2. The tile raster is converted to a data frame with xyz values
3. A data frame with all tiles combined is created, 
4. This all-tiles data frame is converted back to a `las`, 
5. which is then rasterized again using `lidR::rasterize_canopy` with the `p2r` algorithm to select the highest point in a raster tile. 
This could result in i) empty cells; and/or ii) a less smooth DTM which is influenced by artifact points (especially since the current outlier removal is applied only to the non-ground points *after* the classification algorithm is applied). Furthermore, as a  DTM is created for each tile separately, there is potential for edge effects to be amplified across the study extent. Calculating the DTM for each tile separately excludes valid data which would be otherwise available to the algorithm if processed altogether. A potential solution is to continue processing by grid tiles with a buffer that overlaps with neighboring tiles, use a multi-point interpolation algorithm (e.g. `knnidw`) on each buffered tile, and then combine the grid tile rasters via `terra::mosaic` where values in overlapping cells are averaged. Or, process as a single point cloud over the entire study extent.</span>

```{r create-chm-fn}
# GW added
# create funtion to read las, rasterize, and return data frame
las2chm2df <- function(las_path_name, des_chm_res = 3, min_z = -Inf, max_z = Inf) {
  ### Read in the file
  las_norm_tile = lidR::readLAS(las_path_name, select = "xyzc")
  
  ### Filter the points to within the min and max Z range 
    las_norm_tile = lidR::filter_poi(las_norm_tile, Z > as.numeric(min_z))
    las_norm_tile = lidR::filter_poi(las_norm_tile, Z < as.numeric(max_z))
    
  ### Get a logic check 
  is_las_empty = lidR::is.empty(las_norm_tile)
  
  ### If the las file is empty, return NULL
  if(is_las_empty == TRUE){return(
    data.frame(
      X=as.numeric(NULL)
      , Y=as.numeric(NULL)
      , Z=as.numeric(NULL)
    )
  )}else{
    ### Create a CHM from the file
    chm_tile = lidR::rasterize_canopy(
      las_norm_tile
      , res = des_chm_res
      , algorithm = p2r()
      , pkg = "terra"
    )
    
    ### Get the DEM points
    chm_points = as.data.frame(chm_tile, xy = T) %>% 
      dplyr::rename_with(toupper)
    
    ### Return the points to the function 
    return(chm_points)
  }
}
## map files over the function
# list.files(config$las_norm_tile_dir, pattern = ".*\\.(laz|las)$", full.names = T) %>%
#   .[2:3] %>%
#   purrr::map(las2chm2df, des_chm_res = 3) %>%
#   dplyr::bind_rows() %>%
#   str()
#   # dplyr::pull(Z) %>% 
#   # max(na.rm=T)
  

### Function to get CHM from height normalized tiles
rasterize_tiles_to_chm = function(
  config
  , my_des_chm_res = 3 #in meters
  , calculate_extent = TRUE
  , my_las_grid = las_grid # generate_grid_over_extent(las_ctg, desired_tile_res)
  , my_las_ctg = las_ctg # lidR::readLAScatalog(config$input_las_dir)
  , my_min_z = -Inf
  , my_max_z= Inf
){
  # define files
  las_grid = my_las_grid
  las_ctg = my_las_ctg
  
  message(" --- Initializing canopy height model rasterization --- ")
  master_start = Sys.time()
  
  # ###_____________________________###
  # ### Read in the las grid object ###
  # ###_____________________________###
  # ## !!!!!!! the grid is already in memory, no need to re-read 
  # message("Reading in project grid ... ")
  # las_grid = sfarrow::st_read_parquet(paste0(
  #   config$las_grid_dir
  #   , "/"
  #   , "project_grid.parquet")
  # )
  # 
  # message("Reading in the las as a lascatalog for indexing ... ")
  # las_ctg = lidR::readLAScatalog(config$input_las_dir)
  # las_ctg
  
  ###_______________________________________________________________________________###
  ### Get a list of classified ground normalized tiles to generate CHM raster files ###
  ###_______________________________________________________________________________###
  ### Loop through and generate DTM data.frame for each tile and then bind_rows
  start_time = Sys.time()
  # file list
  tile_list = list.files(config$las_norm_tile_dir, pattern = ".*\\.(laz|las)$", full.names = T)
  # map las2chm2df function
  merged_chm_points = tile_list %>%
    purrr::map(las2chm2df, des_chm_res = my_des_chm_res, min_z = my_min_z, max_z = my_max_z) %>%
    # .[2:3] %>%
    dplyr::bind_rows()
  ###_____________________________________###
  ### Make a las file from the CHM points ###
  ###_____________________________________###
  
  message("Generating the CHM las file ... ")
  des_crs = sf::st_crs(las_grid)
  las = lidR::LAS(merged_chm_points)
  sf::st_crs(las) = des_crs
  # las
  
  ### Write cleaned las to the disk
  message("Writing the CHM las file to the disk ... ")
  lidR::writeLAS(
    las
    , file = paste0(
      config$delivery_las_dir
      , "/master_chm_point_cloud_z"
      , as.character(my_min_z)
      , "to"
      , as.character(my_max_z)
      , ".laz"
    )
  )
  
  las_area_m2 = lidR::area(las)
  las_area_acres = las_area_m2/4047
  message("Total merged CHM area of ", las_area_acres, " acres .... ")
  
  ###____________________________________###
  ### Generate a CHM from the CHM points ###
  ###____________________________________###
  
  message("Generating the CHM raster file ... ")
  master_chm = lidR::rasterize_canopy(las, res = my_des_chm_res, algorithm = p2r(), pkg="terra")
  # master_chm
  
  ###_____________________________________###
  ### Write the master raster to the disk ###
  ###_____________________________________###
  
  message("Writing the CHM raster file to the disk ... ")
  outname = paste0(
    config$delivery_spatial_dir
    ,"/chm_raster_z"
    , as.character(my_min_z)
    , "to"
    , as.character(my_max_z)
    , "m_res"
    , my_des_chm_res
    , "m.tif"
    
  )
  terra::writeRaster(master_chm, outname, overwrite = TRUE)
  
  ###_______________________________________###
  ### Get a polygon of the full file extent ###
  ###_______________________________________###
  
  if(calculate_extent == TRUE){
    
    message("Getting the extent of the CHM file ... ")
    extent_raster = terra::clamp(master_chm, 1, 1, 1)
    extent_poly = terra::as.polygons(extent_raster)
    extent_poly = terra::simplifyGeom(extent_poly)
    extent_poly = terra::fillHoles(extent_poly)
    extent_poly = sf::st_as_sf(extent_poly)
    extent_poly = st_union(extent_poly)
    extent_poly = st_as_sf(extent_poly)
    # extent_poly
    
    ### Write the poly to the disk
    #sf::st_write(extent_poly, dsn = "chm_extent_kml.kml", delete_dsn = TRUE, quiet = TRUE)
    sf::st_write(
      extent_poly
      , dsn = paste0(
        config$working_spatial_dir
        , "/chm_extent_geopackage.gpkg"
      )
      , delete_dsn = TRUE, quiet = TRUE
    )
    
  }
  
  ###____________________###
  ### Get the total time ###
  ###____________________###
  
  end_time = Sys.time()
  total_time = difftime(end_time, start_time, units = c("mins"))
  message(" --- Total lidar rasterization took ", total_time, " minutes --- ")
  return(master_chm)
}

```

Call the function to create the CHM

```{r create-chm, results='hide', fig.show='hide', message=FALSE}
master_chm = rasterize_tiles_to_chm(
  config = config
  , my_des_chm_res = desired_chm_res #0.25 #in meters
  , calculate_extent = F
  , my_las_grid = las_grid # generate_grid_over_extent(las_ctg, desired_tile_res)
  , my_las_ctg = las_ctg # lidR::readLAScatalog(config$input_las_dir)
  , my_min_z = -Inf
  , my_max_z= max_height_threshold
)
```

Map the CHM

```{r map-chm}
terra::rast(paste0(
    config$delivery_spatial_dir
    ,"/chm_raster_z"
    , as.character(-Inf)
    , "to"
    , as.character(max_height_threshold)
    , "m_res"
    , desired_chm_res
    , "m.tif"
  )) %>%
  stars::st_as_stars() %>% 
  mapview::mapview(
    layer.name = "CHM ht (m)"
    , alpha.regions = 0.6
  )
# # uncomment for ggplot
#   as.data.frame(xy=T) %>% 
#   dplyr::rename_with(tolower) %>% 
#   dplyr::rename(f=3) %>% 
#   ggplot(mapping = aes(x=x,y=y,fill=f)) +
#     geom_tile() +
#     scale_fill_viridis_c(na.value = "black") +
#     labs(fill = "elevation (m)") +
#     theme_void()
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

# Create *Stem-Only* Canopy Height Model{#create_stem_chm}

This section uses the height normalized point cloud grid tiles (created in [this section](#classify_points)) to create a CHM raster using only points between a specified height based on the program defined in [this section](#create_chm). The stem section at DBH includes points that fall between 1.2 and 1.4 meters.

<span style="color: red;">George W. notes: it is unclear what this data is used for...the `las` file may be used to extract DBH measurements using the `TreeLS` package. See page 3 of [Swayze and Tinkham (2022)](https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=10655866445299954513). However, it is likely that the point cloud would need to be filtered based on point color to ensure extraction of stem points and not understory (e.g. tree regeneration) points.</span>

Call the function to create the *stem-only* CHM

```{r create-stem-chm, results='hide', fig.show='hide', message=FALSE}
###_____________________________________________________###
### Rasterize the stem section at DBH to stem CHM tiles ###
###_____________________________________________________###
rasterize_tiles_to_chm(
  config = config
  , my_des_chm_res = 0.5 #0.07 #in meters
  , calculate_extent = F
  , my_las_grid = las_grid # generate_grid_over_extent(las_ctg, desired_tile_res)
  , my_las_ctg = las_ctg # lidR::readLAScatalog(config$input_las_dir)
  , my_min_z = 1.2
  , my_max_z= 1.4
)
```

Map the *stem-only* CHM

```{r map-stem-chm}
terra::rast(paste0(
    config$delivery_spatial_dir
    ,"/chm_raster_z"
    , as.character(1.2)
    , "to"
    , as.character(1.4)
    , "m_res"
    , as.character(0.5)
    , "m.tif"
  )) %>%
  # terra::aggregate(fact = 20, fun = "mean") %>%
  stars::st_as_stars() %>% 
  mapview::mapview(
    layer.name = "stem-only ht (m)"
    , alpha.regions = 0.6
  )
# # uncomment for ggplot
#   as.data.frame(xy=T) %>% 
#   dplyr::rename_with(tolower) %>% 
#   dplyr::rename(f=3) %>% 
#   ggplot(mapping = aes(x=x,y=y,fill=f)) +
#     geom_tile() +
#     scale_fill_viridis_c(na.value = "black") +
#     labs(fill = "elevation (m)") +
#     theme_void()
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

# Detect Stems{#detect-stems}

This process uses the normalized grid tiled `laz` files created in [this section](#classify_points) to detect tree stems using the `TreeLS` package based on methods described in [de Conto et al. (2017)](https://scholar.google.com/scholar?cluster=4008845887457503672&hl=en&as_sdt=0,6). This section (and the coded functions included within) which relies on the `TreeLS` package requires that data be stored within the R environment until all steps reliant on `TreeLS` functions are completed. Writing out `laz` files (i.e. for later `TreeLS` processing) strips all information that is required for further processing using `TreeLS`. It may be possible to save a `csv` file with the required `TreeLS` attributes alongside the `laz` file and then combine these data during later processing with the `TreeLS` package but the authors have not tested this.

Each normalized grid tile point cloud is individually passed to the `TreeLS::treeMap` function using the `map.hough` algorithm to estimate tree occurrence regions from a normalized point cloud using the Hough Transform for circle search. Good methods for noise filtering are paramount for a robust stem isolation algorithm. There are a handful of methods to remove noise from stem point cloud data; one technique is the Hough transformation technique in which every data point "votes" for a cylinder center ([de Conto et al. (2017)](https://scholar.google.com/scholar?cluster=4008845887457503672&hl=en&as_sdt=0,6)). The specific tree detection function is implemented using the following code:

```{r treemap-ex, include=TRUE, eval=FALSE}
TreeLS::treeMap(
  las = las_norm_tile
  , method = map.hough(
    # height thresholds applied to filter a point cloud before processing
    min_h = 1
    , max_h = 5
    # height interval to perform point filtering/assignment/classification
    , h_step = 0.5
    # pixel side length to discretize the point cloud layers 
      # while performing the Hough Transform circle search
    , pixel_size = 0.025
    # largest tree diameter expected in the point cloud
    , max_d = 0.75 # 0.75m = 30in
    # minimum point density (0 to 1) within a pixel evaluated 
      # on the Hough Transform - i.e. only dense point clousters will undergo circle search
      # hey google, define "clouster" ?
    , min_density = 0.0001
    # minimum number of circle intersections over a pixel 
      # to assign it as a circle center candidate.
    , min_votes = 3
  )
  # parameter passed down to treeMap.merge (if merge > 0)
  , merge = 0
)
```

After tree detection, the tree coordinates that overlap (or are too close) are merged into a single tree ID using the `TreeLS::treeMap.merge` function. The detected trees are then used to assign tree IDs to the original normalized point cloud based on coordinates extracted from the `TreeLS::treeMap` object via `TreeLS::treePoints(las=las_norm_tile, map=treemap_merge, method = trp.crop(l = 3))`, where the `trp.crop()` algorithm assigns points to a tree ID that are inside a circle of fixed area (i.e. 3m) around the `TreeLS::treeMap` object. 

In the next step, points in the normalized point cloud are classified as stem points and assigned a tree ID using the `TreeLS::stemPoints` function with the algorithm `stm.hough`:

```{r stempt-ex, include=TRUE, eval=FALSE}
TreeLS::stemPoints(
  las = las
  , method = stm.hough(
    # height interval to perform point filtering/assignment/classification.
    h_step = 0.5
    # largest tree diameter expected in the point cloud
    , max_d = 0.75 # 0.75m = 30in
    # tree base height interval to initiate circle search
    , h_base = c(1, 2.5)
    #  pixel side length to discretize the point cloud layers 
      # while performing the Hough Transform circle search.
    , pixel_size = 0.025
    # minimum point density (0 to 1) within a pixel evaluated 
      # on the Hough Transform - i.e. only dense point clousters will undergo circle search
      # hey google, define "clouster" ?
    , min_density = 0.1
    # minimum number of circle intersections over a pixel 
      # to assign it as a circle center candidate.
    , min_votes = 3
  )
)
```

Lastly, the normalized point cloud with points assigned to a tree ID (where a stem was detected) and points classified as stems is used to estimate the DBH.

DBH estimation is done using the `TreeLS::tlsInventory` function with using a 2D circle fitting algorithm (i.e. `ransac`). The specific function call used is: 

```{r ex-dbh-fit, include=TRUE, eval=FALSE}
TreeLS::tlsInventory(
  las = las
  # height layer (above ground) to estimate stem diameters, in point cloud units
  , dh = 1.37
  # height layer width, in point cloud units
  , dw = 0.2
  # parameterized shapeFit function, i.e. method to use for diameter estimation.
  , d_method = shapeFit(
    # either "circle" or "cylinder".
    shape = "circle"
    # optimization method for estimating the shape's parameters
    , algorithm = "ransac"
    # number of points selected on every RANSAC iteration.
    , n = 20
  )
)
```

## Define the stem detection function{#detect_stem_fn}

```{r detect-stem-fn}
###_____________________________________________________###
### Define function to map for potential tree locations ###
### Using TreeLS::treeMap                               ###
###_____________________________________________________###
### Function to map for potential tree locations with error handling
  tree_map_function <- function(las){
    result <- tryCatch(
      expr = {
        map = TreeLS::treeMap(
          las = las
          , method = map.hough(
            # height thresholds applied to filter a point cloud before processing
            min_h = 1
            , max_h = 5
            # height interval to perform point filtering/assignment/classification
            , h_step = 0.5
            # pixel side length to discretize the point cloud layers 
              # while performing the Hough Transform circle search
            , pixel_size = 0.025
            # largest tree diameter expected in the point cloud
            , max_d = 0.75 # 0.75m = 30in
            # minimum point density (0 to 1) within a pixel evaluated 
              # on the Hough Transform - i.e. only dense point clousters will undergo circle search
              # hey google, define "clouster" ?
            , min_density = 0.0001
            # minimum number of circle intersections over a pixel 
              # to assign it as a circle center candidate.
            , min_votes = 3
          )
          # parameter passed down to treeMap.merge (if merge > 0)
          , merge = 0
        )
      },
      error = function(e) {
        message <- paste("Error:", e$message)
        return(message)
      }
    )
    if (inherits(result, "error")) {
      return(result)
    } else {
      return(result)
    }
  }
```

## Define the write stem function

This function combines `TreeLS` processing to the normalized point cloud to: 

1) Apply the `TreeLS::treeMap` [stem detection function](#detect_stem_fn)
2) Merge overlapping tree coordinates using `TreeLS::treeMap.merge`
3) Assign tree IDs to the original points using `TreeLS::treePoints`
4) Flag only the stem points using `TreeLS::stemPoints`
5) DBH estimation is done using `TreeLS::tlsInventory`

The result writes i) a `laz` to the `r config$las_stem_dir` directory with the `Classification` data updated to: ground points (class 2); water points (class 9); stem points (class 4); non-stem (class 5). Also written is a `parquet` file with the tree identification stem locations, heights, and DBH estimates.

```{r write-stem-las-fn}
# pass this function a file path of the normalized las you wish to detect stems and classify
write_stem_las_fn <- function(las_path_name) {
    ### Get the desired las file
    las_name = basename(las_path_name)
    # las_name
    
    ### See if the las file has been generated
    path_to_check = paste0(config$las_stem_dir, "/", las_name)
    does_file_exist = file.exists(path_to_check)
    # does_file_exist
    ### See if the vector file has been generated
    path_to_check = paste0(config$stem_poly_tile_dir, "/", tools::file_path_sans_ext(las_name), ".parquet")
    does_file_exist2 = file.exists(path_to_check)
    # does_file_exist2
    
    if(does_file_exist == TRUE & does_file_exist2 == TRUE){
      message("stem detect for grid number ", las_name, " already exists guy ... ")
      return(FALSE)
    }
    
    ### Read in the desired las file
    las_norm_tile = lidR::readLAS(las_path_name)
    las_norm_tile = lidR::filter_duplicates(las_norm_tile)
    # plot(las_norm_tile)
    
    # get the maximum point height
    max_point_height = max(las_norm_tile@data$Z)
    
    ###____________________________________________________________###
    ### If the max point height is below X feet, return classified tile ###
    ###____________________________________________________________###
    
    if(max_point_height < 2){
        message("No points >2m for grid number ", las_name, " so skipped it ... ")
        # ### !!!! UNCOMMENT TO WRITE CLASSIFIED LAS INSTEAD WITH NO STEM POINTS
        # ### Pull out the ground points
        # ground = filter_poi(las_norm_tile, Classification == 2)
        # 
        # ### Pull out the remaining points that arent ground
        # remaining_points = filter_poi(las_norm_tile, Classification != 2)
        # remaining_points@data$Classification = 5
        # 
        # ### Combine the newly classified data
        # las_reclassified = rbind(ground, remaining_points)
        # las_reclassified@data$TreeID = as.numeric(0)
        # las_reclassified@data$Stem = as.logical(F)
        # las_reclassified@data$Segment = as.numeric(0)
        # las_reclassified@data$Radius = as.numeric(0)
        # las_reclassified@data$Votes = as.numeric(0)
        # 
        # ### Write the stem points to the disk
        # lidR::writeLAS(las_reclassified, paste0(config$las_stem_dir, "/", las_name))
      return(FALSE)
    }
    
    ###______________________________________________________________###
    ### If the max point height is above X feet, try to detect stems ###
    ###______________________________________________________________###
    
    if(max_point_height >= 2){
      ###______________________________________________________________###
      ### 1) Apply the `TreeLS::treeMap` [stem detection function](#detect_stem_fn)
      ###______________________________________________________________###
      ### Run the function to search for candidate locations
      treemap_temp = tree_map_function(las_norm_tile)
      
      ### Get a logic check
      check = class(treemap_temp)
      # check
      
      ###_______________________________________________________________###
      ### If the class of the result === Character, then no stems found ###
      ###_______________________________________________________________###
      
      if(check == "character"){
        message("No stems detected for grid number ", las_name, " so skipped it ... ")
        return(FALSE)
      }
      
      ### If the class of the result == "LAS"
      if(check == "LAS"){
        
        ###___________________________________###
        ### Classify the tree and stem points ###
        ###___________________________________###
        
        ###______________________________________________________________###
        ### 2) Merge overlapping tree coordinates using `TreeLS::treeMap.merge`
        ###______________________________________________________________###
        treemap_temp = TreeLS::treeMap.merge(treemap_temp)
        
        ###______________________________________________________________###
        ### 3) Assign tree IDs to the original points using `TreeLS::treePoints`
        ###______________________________________________________________###
        ### Classify tree regions
        ## Assigns TreeIDs to a LAS object based on coordinates extracted from a treeMap object.
        las_norm_tile = TreeLS::treePoints(
          las = las_norm_tile
          , map = treemap_temp
          , method = trp.crop(l = 3)
        )
        # plot(las_norm_tile, color = "TreeID")
        
        ###______________________________________________________________###
        ### 4) Flag only the stem points using `TreeLS::stemPoints`
        ###______________________________________________________________###
        ### Classify stem points
        las_norm_tile = TreeLS::stemPoints(
          las = las_norm_tile
          , method = stm.hough(
            # height interval to perform point filtering/assignment/classification.
            h_step = 0.5
            # largest tree diameter expected in the point cloud
            , max_d = 0.75 # 0.75m = 30in
            # tree base height interval to initiate circle search
            , h_base = c(1, 2.5)
            #  pixel side length to discretize the point cloud layers 
              # while performing the Hough Transform circle search.
            , pixel_size = 0.025
            # minimum point density (0 to 1) within a pixel evaluated 
              # on the Hough Transform - i.e. only dense point clousters will undergo circle search
              # hey google, define "clouster" ?
            , min_density = 0.1
            # minimum number of circle intersections over a pixel 
              # to assign it as a circle center candidate.
            , min_votes = 3
          )
        )
        
        ###______________________________________________________________###
        ### 5) DBH estimation is done using `TreeLS::tlsInventory`
        ###______________________________________________________________###
        ### Search through tree points and estimate DBH to return a data frame of results
          tree_inv_df = TreeLS::tlsInventory(
            las = las_norm_tile
            # height layer (above ground) to estimate stem diameters, in point cloud units
            , dh = 1.37
            # height layer width, in point cloud units
            , dw = 0.2
            # parameterized shapeFit function, i.e. method to use for diameter estimation.
            , d_method = shapeFit(
              # either "circle" or "cylinder".
              shape = "circle"
              # optimization method for estimating the shape's parameters
              , algorithm = "ransac"
              # number of points selected on every RANSAC iteration.
              , n = 20
            )
          )
          # class(tree_inv_df)
          # tree_inv_df %>% dplyr::glimpse()
        ###_______________________________________________________###
        ### clean up the DBH stem data frame ###
        ###_______________________________________________________###
          # add details to table and convert to sf data
          tree_inv_df = tree_inv_df %>% 
            dplyr::mutate(
              Radius = as.numeric(Radius)
              , dbh_m = Radius*2
              , dbh_cm = dbh_m*100
              , basal_area_m2 = pi * (Radius)^2
              , basal_area_ft2 = basal_area_m2 * 10.764
              , treeID = paste0(X, "_", Y)
              , stem_x = X
              , stem_y = Y
            ) %>% 
            sf::st_as_sf(coords = c("X", "Y"), crs = sf::st_crs(las_norm_tile)) %>% 
            dplyr::select(
              treeID, H, , stem_x, stem_y, Radius, Error
              , dbh_m, dbh_cm, basal_area_m2, basal_area_ft2
            ) %>% 
            dplyr::rename(
              tree_height_m = H
              , radius_m = Radius
              , radius_error_m = Error
            )
          # tree_inv_df %>% dplyr::glimpse()
          
          ### Remove points outside the bounding box of the laz tile + 1m buffer
          tree_inv_df = tree_inv_df %>% 
            sf::st_crop(
              sf::st_bbox(las_norm_tile) %>% 
                sf::st_as_sfc() %>% 
                sf::st_buffer(1)
            )
        
        ###_______________________________________________________###
        ### Set the classification codes of different point types ###
        ###_______________________________________________________###
        
        ### Pull out the stem files
        stem_points = lidR::filter_poi(las_norm_tile, Stem == TRUE)
        stem_points@data$Classification = 4
        
        ### Pull out the ground points
        ground = filter_poi(las_norm_tile, Classification %in% c(2,9))
        
        ### Pull out the remaining points that arent ground
        remaining_points = filter_poi(las_norm_tile, Stem == FALSE & !(Classification %in% c(2,9)))
        remaining_points@data$Classification = 5
        
        ### Combine the newly classified data
        las_reclassified = rbind(stem_points, ground, remaining_points)
        # str(las_reclassified)
        # class(las_reclassified)
        # plot(las_reclassified, color = "Classification")
        
        ###_______________________________________________________###
        ### Write output to disk ###
        ###_______________________________________________________###
        ### Write the stem points to the disk
        lidR::writeLAS(las_reclassified, paste0(config$las_stem_dir, "/", las_name))
        message("Wrote stem detect laz for grid number ", las_name, " successfully ... ")
        ### Write stem polygons to the disk
        out_name = tools::file_path_sans_ext(las_name)
        out_name = paste0(config$stem_poly_tile_dir, "/", out_name, ".parquet")
        sfarrow::st_write_parquet(tree_inv_df, out_name)
        message("Wrote stem detect vector data for grid number ", las_name, " successfully ... ")
        
        # return(las_norm_tile)
        return(TRUE)
      }
    }
}
# ### test the function
# list.files(config$las_norm_tile_dir, pattern = ".*\\.(laz|las)$", full.names = T) %>%
#   .[1:2] %>%
#   purrr::map(write_stem_las_fn)
```

Call the function to write the stem classified point clouds to the disk

```{r call-detect-stems, message=FALSE, warning=FALSE, results='hide'}
# map over the normalized point cloud tiles
  list.files(config$las_norm_tile_dir, pattern = ".*\\.(laz|las)$", full.names = T) %>%
    purrr::map(write_stem_las_fn)
```

## Example of Detect Stems Steps

This is an example of the full process: 

### 1. Read Normalized Point Cloud

```{r detect-stem-st1, webgl=FALSE, eval=T}
# read single data tile
  las_norm_tile_temp = list.files(
      config$las_norm_tile_dir
      , pattern = ".*\\.(laz|las)$", full.names = T
    ) %>% 
    .[1] %>% 
    lidR::readLAS() %>% 
    lidR::filter_duplicates()

# plot(las_norm_tile_temp)
plot3D::scatter3D(
  x = las_norm_tile_temp@data$X
  , y = las_norm_tile_temp@data$Y
  , z = las_norm_tile_temp@data$Z
  , colvar = las_norm_tile_temp@data$Z
  , pch = 19, cex = 0.2
)
```

### 2. Detect Stems

```{r detect-stem-st2, webgl=FALSE, eval=T}
# implement the tree detection function
# this function is essentially TreeLS::treeMap(las, method = map.hough(...))
  treemap_temp = tree_map_function(las_norm_tile_temp)
  # what is this?
  # class(treemap_temp)
  # str(treemap_temp)
  
  ## merge TreeIDs which are too close in a treeMap's object.
  treemap_temp = TreeLS::treeMap.merge(treemap_temp)
  # str(treemap_temp)
  # treemap_temp@data$TreeID %>% unique() %>% length()

# plot(treemap_temp, color = "TreeID")
plot3D::scatter3D(
  x = treemap_temp@data$X
  , y = treemap_temp@data$Y
  , z = treemap_temp@data$Z
  , colvar = treemap_temp@data$TreeID
  , col = viridis::viridis(treemap_temp@data$TreeID %>% unique() %>% length())
  , pch = 19, cex = 0.5
)
```

```{r, include=FALSE, eval=FALSE}
plot3D::scatter3D(
  x = treemap_temp@data$X
  , y = treemap_temp@data$Y
  , z = treemap_temp@data$Z
  , colvar = treemap_temp@data$TreeID
  , col = viridis::viridis(treemap_temp@data$TreeID %>% unique() %>% length())
  , pch = 19, cex = 0.5
)
```

### 3. Assign TreeID to Normalized Points

```{r detect-stem-st3, webgl=FALSE, eval=T}
### Classify tree regions
  ## Assigns TreeIDs to a LAS object based on coordinates extracted from a treeMap object.
  las_norm_tile_temp = las_norm_tile_temp %>% 
    TreeLS::treePoints(map = treemap_temp, method = trp.crop(l = 3))
  # las_cls_temp@data %>% dplyr::glimpse()
  # las_cls_temp@data %>% dplyr::count(TreeID) %>% nrow()

# plot(las_norm_tile_temp, color = "TreeID")
plot3D::scatter3D(
  x = las_norm_tile_temp@data$X
  , y = las_norm_tile_temp@data$Y
  , z = las_norm_tile_temp@data$Z
  , colvar = las_norm_tile_temp@data$TreeID
  , col = viridis::viridis(las_norm_tile_temp@data$TreeID %>% unique() %>% length())
  , pch = 19, cex = 0.2
)
```

### 4. Classify Normalized Points as Stem Points

```{r detect-stem-st4, webgl=FALSE, eval=T}
### Classify stem points
  las_norm_tile_temp = TreeLS::stemPoints(
    las = las_norm_tile_temp
    , method = stm.hough(
      # height interval to perform point filtering/assignment/classification.
      h_step = 0.5
      # largest tree diameter expected in the point cloud
      , max_d = 0.75 # 0.75m = 30in
      # tree base height interval to initiate circle search
      , h_base = c(1, 2.5)
      #  pixel side length to discretize the point cloud layers 
        # while performing the Hough Transform circle search.
      , pixel_size = 0.025
      # minimum point density (0 to 1) within a pixel evaluated 
        # on the Hough Transform - i.e. only dense point clousters will undergo circle search
        # hey google, define "clouster" ?
      , min_density = 0.1
      # minimum number of circle intersections over a pixel 
        # to assign it as a circle center candidate.
      , min_votes = 3
    )
  )
  # las_norm_tile_temp@data %>% dplyr::glimpse()
  # las_norm_tile_temp@data %>% dplyr::count(Classification)
  # las_norm_tile_temp@data %>% dplyr::count(Stem)
  # las_norm_tile_temp@data %>% dplyr::count(TreeID) %>% nrow()
# plot only ground points and stem points
  # lidR::filter_poi(las_norm_tile_temp, (Stem==TRUE | Classification==2)) %>%
  #   plot(color = "Stem")
# plot only ground points and stem points
plt_las_norm_tile_temp = lidR::filter_poi(las_norm_tile_temp, (Stem==TRUE | Classification==2))
plot3D::scatter3D(
  x = plt_las_norm_tile_temp@data$X
  , y = plt_las_norm_tile_temp@data$Y
  , z = plt_las_norm_tile_temp@data$Z
  , colvar = plt_las_norm_tile_temp@data$Stem
  , col = viridis::viridis(plt_las_norm_tile_temp@data$Stem %>% unique() %>% length())
  , pch = 19, cex = 0.4
)
```

### 5. Estimate DBH from the Stem Points{#ex_est_dbh}

```{r detect-stem-st5, webgl=FALSE, eval=T}
### Search through tree points and estimate DBH to return a data frame of results
  tree_inv_temp = TreeLS::tlsInventory(
    las = las_norm_tile_temp
    # height layer (above ground) to estimate stem diameters, in point cloud units
    , dh = 1.37
    # height layer width, in point cloud units
    , dw = 0.2
    # parameterized shapeFit function, i.e. method to use for diameter estimation.
    , d_method = shapeFit(
      # either "circle" or "cylinder".
      shape = "circle"
      # optimization method for estimating the shape's parameters
      , algorithm = "ransac"
      # number of points selected on every RANSAC iteration.
      , n = 20
    )
  )
  # class(tree_inv_temp)
  # tree_inv_temp %>% dplyr::glimpse()
  
  # add details to table and convert to sf data
  tree_inv_temp = tree_inv_temp %>% 
    dplyr::mutate(
      Radius = as.numeric(Radius)
      , dbh_m = Radius*2
      , dbh_cm = dbh_m*100
      , basal_area_m2 = pi * (Radius)^2
      , basal_area_ft2 = basal_area_m2 * 10.764
      , treeID = paste0(X, "_", Y)
      , stem_x = X
      , stem_y = Y
    ) %>% 
    sf::st_as_sf(coords = c("X", "Y"), crs = sf::st_crs(las_norm_tile_temp)) %>% 
    dplyr::select(
      treeID, H, , stem_x, stem_y, Radius, Error
      , dbh_m, dbh_cm, basal_area_m2, basal_area_ft2
    ) %>% 
    dplyr::rename(
      tree_height_m = H
      , radius_m = Radius
      , radius_error_m = Error
    )
  # tree_inv_temp %>% dplyr::glimpse()
  
  ### Remove points outside the bounding box of the laz tile + 1m buffer
  tree_inv_temp = tree_inv_temp %>% 
    sf::st_crop(
      sf::st_bbox(las_norm_tile_temp) %>% 
        sf::st_as_sfc() %>% 
        sf::st_buffer(1)
    )
  
  ### plot
  ggplot() + 
    geom_sf(
      data = sf::st_bbox(las_norm_tile_temp) %>% 
        sf::st_as_sfc() %>% 
        sf::st_buffer(1)
      , lwd = 1.5
      , alpha = 0
    ) +
    geom_sf(
      data = tree_inv_temp
      , mapping = aes(size=dbh_m, color=dbh_m)
    ) + 
    scale_color_viridis_c(option="mako",direction = -1) +
    theme_light()
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

# Combine the Stem Grid Tiles{#combine_stems}

In the [prior section](#detect-stems), each normalized grid tile point cloud was individually analyzed with a `TreeLS` package workflow to: i) write a `laz` to the `r config$las_stem_dir` (`config$las_stem_dir`) directory with the `Classification` data updated to: ground points (class 2); water points (class 9); stem points (class 4); non-stem (class 5); and ii) write a `parquet` file with the tree identification stem locations, heights, and DBH estimates.

This section combines these classified grid tile point clouds into a single point cloud that includes stem points only (`Classification == 4`) and a single vector data layer with the stem locations and identifying information.

## Combine Stem Point Clouds

If stem cloud points spatially overlap duplicate points are removed. This data does not contain tree ID, tree height, or tree DBH estimates. That data resides in the vector data written to the `r config$stem_poly_tile_dir` (`config$stem_poly_tile_dir`) directory as `parquet` tile files created in [this section](#detect-stems). See the example vector data [here](#ex_est_dbh). This vector data is combined in the [next section](#combine_stems_vect).

```{r combine-stems}
###___________________________________________________###
### create function to read las and return data frame
###___________________________________________________###
  las2df <- function(las_path_name, class_filter_list = as.numeric(NA)) {
    ### Read in the desired las file
    las_stem_tile = lidR::readLAS(las_path_name) %>% 
      lidR::filter_duplicates()
  
    # if las classification is null return whole data set
    if(max(is.na(as.numeric(class_filter_list)))==1){
      stem_point_df = las_stem_tile@data %>% 
        # track tile file name
        dplyr::mutate(las_stem_dir_file = basename(las_path_name))
    }else{
      ### Grab the filtered dataframe
      stem_point_df = las_stem_tile@data %>% 
        ### Pull the stem only points
        dplyr::filter(Classification %in% as.numeric(class_filter_list)) %>% 
        # track tile file name
        dplyr::mutate(las_stem_dir_file = basename(las_path_name))
    }
    # str(stem_point_df)
    
    ### Return the dataframe
    return(stem_point_df)
  }
  # ## test function
  # list.files(config$las_stem_dir, pattern = ".*\\.(laz|las)$", full.names = T) %>%
  #   .[1:2] %>% 
  #   purrr::map(las2df, class_filter_list=c(4)) %>% 
  #   dplyr::bind_rows() %>% 
  #   dplyr::count(Classification)

###___________________________________________________###
### Call the function to Merge the stem las point files into a single file ###
###___________________________________________________###
  merged_stem_points = list.files(config$las_stem_dir, pattern = ".*\\.(laz|las)$", full.names = T) %>%
    purrr::map(las2df, class_filter_list=c(4)) %>% 
    dplyr::bind_rows()

  # str(merged_stem_points)
###___________________________________________________###
### Points to LAS
###___________________________________________________###
  stem_points_las = lidR::LAS(merged_stem_points)
  st_crs(stem_points_las) = st_crs(las_grid)
  stem_points_las = lidR::filter_duplicates(stem_points_las)
  
  # plot(stem_points_las)
  
  ### Write the las file to the disk
  lidR::writeLAS(stem_points_las, paste0(config$delivery_las_dir,"/detected_stem_points.laz"))
```

Plot the combined stems point cloud

```{r plot-combine-stems}
# structure of the merged_stem_points data
dplyr::glimpse(merged_stem_points)
# plot
plot3D::scatter3D(
  x = stem_points_las@data$X
  , y = stem_points_las@data$Y
  , z = stem_points_las@data$Z
  , colvar = stem_points_las@data$Z
  , col = viridis::viridis(50)
  , pch = 19, cex = 0.3
)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
# remove the data frame
remove(merged_stem_points)
remove(list = ls()[grep("_temp",ls())])
gc()
```

## Combine Stem Vector Data{#combine_stems_vect}

Combine the vector data written to the `r config$stem_poly_tile_dir` (`config$stem_poly_tile_dir`) directory as `parquet` tile files created in [this section](#detect-stems). An example of this data is shown [here](#ex_est_dbh). This data contains tree ID, tree height, and tree DBH estimates as well as xy coordinates of the tree stems.

If stem vector points spatially overlap ... ???

```{r combine-stems-vect}
###__________________________________________________________###
### Merge the stem vector location tiles into a single object ###
###__________________________________________________________###
dbh_locations_sf = list.files(config$stem_poly_tile_dir, pattern = ".*\\.parquet$", full.names = T) %>% 
    purrr::map(sfarrow::st_read_parquet) %>% 
    dplyr::bind_rows() %>% 
    sf::st_as_sf() %>% 
    sf::st_make_valid() %>% 
    sf::st_set_crs(sf::st_crs(las_grid))
```

What is the structure of this vector data?

```{r combine-stems-vect-desc1}
str(dbh_locations_sf)
```

Is a row unique by `treeID` ?

```{r combine-stems-vect-desc2}
dbh_locations_sf %>% 
  sf::st_drop_geometry() %>% 
  dplyr::ungroup() %>% 
  dplyr::summarise(
    n_rows = dplyr::n()
    , n_unique_treeID = dplyr::n_distinct(treeID)
  ) %>% 
  kableExtra::kbl() %>% 
  kableExtra::kable_styling()
```

Do stem points overlap spatially?

```{r combine-stems-vect-desc3}
### plot
  ggplot(data = dbh_locations_sf %>% dplyr::mutate(random=runif(dplyr::n()))) +
    geom_sf(
      mapping = aes(size=dbh_m, fill=as.factor(random))
      , shape = 21
      , alpha = 0.6
    ) + 
    scale_fill_viridis_d(option="turbo") +
    theme_light() + 
    theme(legend.position = "none")
```

How do the stem points look on satellite imagery?

*Note, in the map layer the `las_grid_buff` box can be checked to view the buffered grid used for processing the grid tiles*

```{r combine-stems-vect-desc4}
mapview::mapview(
    las_ctg@data$geometry
    , color = "black"
    , lwd = 3, alpha.regions = 0.0, legend = F, label = F
  ) +
  mapview::mapview(
    las_grid_buff
    , zcol = "grid_id"
    , col.regions = viridis::cividis(nrow(las_grid_buff))
    , color = "gray55"
    , alpha.regions = 0.2, lwd = 2, legend = F, label = F, hide = T
  ) +
  mapview::mapview(
    dbh_locations_sf
    , zcol = "treeID"
    , cex = "dbh_m"
    , legend = F
    , label = F
  )
```

## Clean the Stem Vector Data

<span style="color: red;">Note!: this clean-up process uses code from the original author Neal Swayze with no edits.</span>

The cleaning process uses the following steps:

* remove stems with empty radius estimates from the `TreeLS::tlsInventory` DBH estimation step
* remove stems >= DBH threshold set by the user in the parameter `dbh_max_size_m` (`r dbh_max_size_m`m in this example)
* remove stems with empty or invalid xy coordinates

This step also creates a vector file of the stems with points sized by the radius (m) estimate of DBH and writes the vector files to the `r config$working_spatial_dir` (`config$working_spatial_dir`) directory.

```{r combine-stems-vect-cln}
###________________________________________________###
### CLEAN UP THE STEM POLYGONS WITH SOME FILTERING ###
###________________________________________________###
  
  ### Get the NA condition
  is_na = is.na(dbh_locations_sf$radius_m)
  dbh_locations_sf = cbind(dbh_locations_sf, is_na)
  
  ### Drop stems with NA values
  dbh_locations_sf = dbh_locations_sf[dbh_locations_sf$is_na == "FALSE",]
  dbh_locations_sf = subset(dbh_locations_sf, select = -c(is_na))
  
  ### Drop DBHs above set threshold 
  dbh_locations_sf = dbh_locations_sf[dbh_locations_sf$dbh_m < dbh_max_size_m,]
  
  ### Remove empty geometry stem locations
  condition = sf::st_is_empty(dbh_locations_sf)
  dbh_locations_sf = cbind(dbh_locations_sf, condition)
  dbh_locations_sf = dbh_locations_sf[dbh_locations_sf$condition == FALSE,]

###___________________________________________________________###
### create a variable and buffer the points with the radius ###
###___________________________________________________________###
  
  ### Reset the condition
  dbh_locations_sf$condition = rep("detected_stem", nrow(dbh_locations_sf))

  ###K Buffer the points by the radius of the DBH
  dbh_locations_sf_buffer = sf::st_buffer(dbh_locations_sf, dist = dbh_locations_sf$radius_m)

###___________________________________________________________###
### Write the DBHs and the merged canopy polygons to the disk ###
###___________________________________________________________###
  sf:::st_write(
    dbh_locations_sf
    , dsn = paste0(config$working_spatial_dir, "/bottom_up_detected_stem_locations.gpkg")
    , append = FALSE
    , delete_dsn = TRUE
    , quiet = TRUE
  )
  sf:::st_write(
    dbh_locations_sf_buffer
    , dsn = paste0(config$working_spatial_dir, "/bottom_up_detected_stem_locations_buffered.gpkg")
    , append = FALSE
    , delete_dsn = TRUE
    , quiet = TRUE
  )
```

Result of the cleaning process (compare to same table above)

```{r combine-stems-vect-cln_rslt}
dbh_locations_sf %>% 
  sf::st_drop_geometry() %>% 
  dplyr::ungroup() %>% 
  dplyr::summarise(
    n_rows = dplyr::n()
    , n_unique_treeID = dplyr::n_distinct(treeID)
  ) %>% 
  kableExtra::kbl() %>% 
  kableExtra::kable_styling()
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
remove(list = ls()[grep("_temp",ls())])
gc()
```

# CHM Individual Tree Detection{#chm_tree_detect}

This section utilizes the Canopy Height Model (CHM) raster created in [this section](#create_chm) which as a grid resolution of **`r desired_chm_res`m** to perform individual tree detection from the top down (i.e. using raster cell height values). From [The `lidR` Package Book](https://r-lidar.github.io/lidRbook/itd-its.html#itd):

*Individual tree detection (ITD) is the process of spatially locating trees and extracting height information. Individual tree segmentation (ITS) is the process of individually delineating detected trees. In `lidR`, detecting and segmenting functions are decoupled to maximize flexibility. Tree tops are first detected using the `locate_trees()` function, followed crown delineation using `segment_trees()`.*

The CHM is used to perform individual tree detection using the `lidR::locate_trees` function with the `lmf` algorithm which implements a local maximum filter based on the window size (`ws`) parameter with a minimum tree height (`hmin`) parameter of 1.37m. The window size can be fixed or variable and its shape can be square or circular. 

The individual tree detection algorithm recommended in [Swayze and Tinkham (2022)](https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=10655866445299954513) is a local maximum variable window function based on research in ponderosa pine (*Pinus ponderosa*) forests by [Creasy et al. (2021)](https://scholar.google.com/scholar?cluster=10356932785437169630&hl=en&as_sdt=0,6) and [Tinkham and Swayze (2021)](https://scholar.google.com/scholar?cluster=11260597505702247290&hl=en&as_sdt=0,6). This recommended variable window function has the form:

$$
\textrm{variable window radius} = \textrm{pixel height} \times 0.1
$$
This particular variable window radius function with a minimum window size of 2m and a maximum window size of  5m has the shape:

```{r ex-var-window, include=FALSE, eval=TRUE, fig.show='hold'}
library(tidyverse)
f_temp = function(x) {
  y = dplyr::case_when(
    is.na(x) ~ 1e-3 # requires non-null
    , x < 0 ~ 1e-3 # requires positive
    , x < 2 ~ 2 # set lower bound
    , x > 20 ~ 5  # set upper bound
    , TRUE ~ 2 + (x * 0.1)
  )
  return(y)
}
data.frame(
  height_m = seq(0,50,2)
) %>% 
dplyr::mutate(
  window_size_m = f_temp(height_m)
) %>% 
ggplot(mapping = aes(x=height_m, y=window_size_m)) + 
  geom_line() + 
  labs(x="Height (m)", y="Window Size (m)") + 
  scale_y_continuous(limits = c(0,6)) +
  theme_light()
remove(f_temp)
```

```{r, include=FALSE, eval=FALSE}
f_temp <- function(x) {
  y = dplyr::case_when(
    x < 2 ~ 3
    , x > 20 ~ 5
    , TRUE ~ 2.6 * (-(exp(-0.08*(x-2)) - 1)) + 3
  )
  return(y)
}
heights_temp <- seq(-5,30,0.5)
ws_temp <- f_temp(heights_temp)
plot(heights_temp, ws_temp, type = "l",  ylim = c(0,6))
remove(list = ls()[grep("_temp",ls())])
```

A variable window size can be implemented in the `lidR::locate_trees` function via the following code:

```{r ex-locate-trees, eval=FALSE}
# define the variable window function
ws_fn = function(x) {
  y = dplyr::case_when(
    is.na(x) ~ 1e-3 # requires non-null
    , x < 0 ~ 1e-3 # requires positive
    , x < 2 ~ 2 # set lower bound
    , x > 30 ~ 5  # set upper bound
    , TRUE ~ 2 + (x * 0.1)
  )
  return(y)
}

# call the locate trees function and pass the variable window
lidR::locate_trees(
  chm
  , algorithm = lmf(
    ws = ws_fn
    , hmin = 1.37
  )
)
```

## Implement CHM Individual Tree Detection

This function uses the CHM raster created in [this section](#create_chm) and applies the individual tree detection algorithm *using a variable window function of linear form* (with a minimum window size of 2m for pixels 2m and below and a maximum window size of 5m for pixels 30m in height above). The result is a `sf` data frame with point locations of tree tops.

```{r chm-tree-detect}
###___________________________________________________###
### define the variable window function
###___________________________________________________###
# define the variable window function
ws_fn = function(x) {
  y = dplyr::case_when(
    is.na(x) ~ 1e-3 # requires non-null
    , x < 0 ~ 1e-3 # requires positive
    , x < 2 ~ 2 # set lower bound
    , x > 30 ~ 5  # set upper bound
    , TRUE ~ 2 + (x * 0.1)
  )
  return(y)
}

###___________________________________________________###
### Individual tree detection using CHM (top down)
###___________________________________________________###
  # master_chm = rasterize_tiles_to_chm()
  # terra::crs(master_chm)
  # plot(master_chm)
  
  ### ITD on CHM
  # call the locate_trees function and pass the variable window
  tree_tops = lidR::locate_trees(
    master_chm
    , algorithm = lmf(
      ws = ws_fn
      , hmin = minimum_tree_height
    )
  )
  # str(tree_tops)
```

View the results of the individual tree detection overlaid on the CHM raster

```{r plt-chm-tree-detect}
ggplot() + 
  geom_tile(
    data = master_chm %>% as.data.frame(xy=T) %>% dplyr::rename(f=3)
    , mapping = aes(x=x,y=y,fill=f)
  ) +
  geom_sf(
    data = tree_tops
    , shape = 20
    , color = "black"
  ) +
  coord_sf(
    expand = FALSE
  ) +
  scale_fill_viridis_c(option = "plasma") +
  labs(fill = "Hgt. (m)", x = "", y = "") +
  theme_light()
```

# Delineate Tree Crowns

This step uses the [Individual Tree Detection based on the CHM](#chm_tree_detect) to delineate tree crown vector (i.e. polygon) shapes.

*[Creasy et al. (2021)](https://scholar.google.com/scholar?oi=bibs&hl=en&cluster=10356932785437169630)* evaluated four different crown delineation algorithms in ponderosa pine (*Pinus ponderosa*) forests: the Dalponte `lidR::dalponte2016`, Silva `lidR::silva2016`, and watershed `lidR::watershed` algorithms inside the `lidR::segment_trees` function and the marker-controlled watershed function from the `ForestTools` package. Overall, the `lidR::watershed` algorithm provided the smallest crown area bias though small crown areas were overestimated and larger crowns were underestimated.

The `lidR::segment_trees` function works on an input point cloud (i.e. `las`) without the requirement to create a canopy height model (CHM) beforehand. However, the crown delineation algorithms available within the `lidR` package can be run outside of the `lidR::segment_trees` function using only an input CHM raster. From [The `lidR` Package Book](https://r-lidar.github.io/lidRbook/itd-its.html#its-chm):

*While point cloud segmentation is standard in lidR, users may only have access to a CHM. There are many reasons for only using a CHM, and this is why raster-based methods can be run standalone outside segment_trees(). Whether using the point cloud or a raster, segmentation results will be exactly the same. The difference will be the data format of the segmentation result. In lidR, a LAS object will gain a treeID attribute, while for rasters, delineated crowns are returned in a raster format.* To work outside segment_trees() it suffices to call the function standalone like this:

```{r ex-crown-delin, include=TRUE, eval=FALSE}
crowns = lidR::watershed(
  # input raster layer !! works with terra or stars !!
  chm = master_chm
  # threshold below which a pixel cannot be a tree. Default is 2
  , th_tree = 1.37
)

plot(crowns, col = (viridis::turbo(2000) %>% sample()))
```

<span style="color: red;">George W. notes: the `lidR::watershed` call above fails because the input CHM created in [this section](#chm_tree_detect) requires no empty raster cells. Obtaining a CHM raster with unempty cells can be accomplished using the interpolation and mosaic methods discussed in that section. Alternatively, the `lidR::segment_trees` function can be utilized with a point cloud covering the full study extent which requires a complete (non-tiled) point cloud (perhaps using the `laz` file created based off of the CHM raster and written to the disk `r config$delivery_las_dir` directory).</span>

Instead, the `ForestTools::mcws` marker-controlled watershed segmentation algorithm is used below and requires input individual tree top points and a CHM. However, this package relies on the `raster` package which was depreciated in 2023. 

```{r crown-delin}
# this requires the `raster` package which is depreciated
crowns = ForestTools::mcws(
  treetops = sf::st_zm(tree_tops, drop = T) # drops z values
  , CHM = raster::raster(master_chm) # converts to raster data
  , minHeight = 1.37
) %>% terra::rast()
# str(crowns)

# plot the crowns
plot(crowns, col = (viridis::turbo(2000) %>% sample()))
```


```{r, include=FALSE, eval=FALSE}
### Get the treeID fixed for the input seeds
  message("Cleaning up delineated crowns ... ")
  input_seeds_coords = as.data.frame(sf::st_coordinates(input_seeds))
  treeID = paste0(round(input_seeds_coords$X, 1), "_", round(input_seeds_coords$Y, 1))
  input_seeds = subset(input_seeds, select = -c(treeID))
  input_seeds = cbind(input_seeds, treeID)
  input_seeds
  
  ### Convert crown raster to terra rast, then polygons, then to Sf
  crowns = terra::rast(crowns)
  crowns = terra::as.polygons(crowns)
  crowns = terra::makeValid(crowns)
  crowns = terra::simplifyGeom(crowns)
  crowns = terra::fillHoles(crowns)
  crowns = sf::st_as_sf(crowns)
  crowns = sf::st_buffer(crowns, 0)
  
  ### Get the crown area, then remove super small crowns
  message("Getting crown area of polygons ... ")
  crown_area_m2 = as.numeric(sf::st_area(crowns))
  crowns = cbind(crowns, crown_area_m2)
  crowns = crowns[crowns$crown_area_m2 > min_crown_size_m2,]
  crowns
  
  ### Join the crowns with the seeds to append data, remove Nulls
  message("Joining crowns with input tree top seeds ... ")
  crowns = sf::st_join(crowns, input_seeds)
  crowns = subset(crowns, select = -c(layer))
  crowns = sf::st_difference(crowns)
  crowns = subset(crowns, select = c(treeID, Z, crown_area_m2))
  colnames(crowns) = c("treeID", "tree_height_m", "crown_area_m2", "geometry") 
  crowns
  
  ### Add height summaries
  # terra::extract
  # terra::extract(r, v, mean, na.rm = TRUE,weights = TRUE)
  # terra::zonal

  message("Extracting height summaries for each crown ... ")
  mean_crown_ht_m = exactextractr::exact_extract(input_chm, crowns, fun = "mean")
  median_crown_ht_m = exactextractr::exact_extract(input_chm, crowns, fun = "median")
  min_crown_ht_m = exactextractr::exact_extract(input_chm, crowns, fun = "min")
  crowns = cbind(crowns, mean_crown_ht_m, median_crown_ht_m, min_crown_ht_m)
  
  ### Write the crowns to the disk
  message("Writing the crowns to the disk ... ")
  setwd(config$working_spatial_dir)
  sf::st_write(crowns, "top_down_detected_crowns.gpkg", quiet = TRUE, append = FALSE)
  
  ### Get the end time
  end_time = Sys.time()
  total_time = difftime(end_time, start_time, units = c("mins"))
  message("Total top-down crown delineation took ", total_time, " minutes ... ")
  
  
}

```


---

```{r, eval=F, include=F}

###__________________________###
### FUNCTIONS IN DEVELOPMENT ###
###__________________________###

### New function to detect crowns bottom up, independent from main pipeline
detect_crowns_bottom_up = function(config, desired_chm_res, window_size, minimum_height, min_crown_size_m2){
  
  ### Read in the detected stem locations
  start_time = Sys.time()
  
  ### Read in the chm
  setwd(config$delivery_spatial_dir)
  desired_chm_name = paste0("master_chm_raster_", desired_chm_res, "m.tif")
  message("Reading in ", desired_chm_name, " ... ")
  input_file_path = paste0(config$delivery_spatial_dir, "/", desired_chm_name)
  input_chm = terra::rast(input_file_path)
  input_chm
  
  ## Read in the stems
  message("Reading in the detected stem location points ... ")
  path_to_stem_locations = paste0(config$working_spatial_dir, "/bottom_up_detected_stem_locations.gpkg")
  stem_locations = sf::st_read(path_to_stem_locations, quiet = TRUE)
  stem_locations
  
  ### Create Seeds object for delineation
  message("Preparing stem locations for crown delineation ... ")
  input_seeds = subset(stem_locations, select = c(tree_height_m))
  colnames(input_seeds) = c("Z", "geometry")
  treeID = rep(1:nrow(input_seeds))
  input_seeds = cbind(treeID, input_seeds)
  input_seeds
  
  ### Use the tree tops to delineate crowns using MCWS from ForestTools
  message("Detecting crowns from stem location seeds ... ")
  input_chm_raster = raster::raster(input_chm)
  crowns = ForestTools::mcws(input_seeds, input_chm_raster, minHeight = minimum_height, format = "raster")
  crowns
  
  ### Get the treeID fixed for the input seeds
  message("Cleaning up the delineated crowns ... ")
  input_seeds_coords = as.data.frame(sf::st_coordinates(input_seeds))
  treeID = paste0(round(input_seeds_coords$X, 1), "_", round(input_seeds_coords$Y, 1))
  input_seeds = subset(input_seeds, select = -c(treeID))
  input_seeds = cbind(input_seeds, treeID)
  input_seeds
  
  ### Convert crown raster to terra rast, then polygons, then to Sf
  crowns = terra::rast(crowns)
  crowns = terra::as.polygons(crowns)
  crowns = terra::simplifyGeom(crowns)
  crowns = terra::fillHoles(crowns)
  crowns = sf::st_as_sf(crowns)
  crowns = sf::st_buffer(crowns, 0)
  #crowns = sf::st_difference(crowns)
  
  ### Get the crown area, then remove super small crowns
  message("Getting crown area of polygons ... ")
  crown_area_m2 = as.numeric(sf::st_area(crowns))
  crowns = cbind(crowns, crown_area_m2)
  crowns = crowns[crowns$crown_area_m2 > min_crown_size_m2,]
  
  ### Join the crowns with the seeds to append data, remove Nulls
  message("Joining crowns with input tree top seeds ... ")
  stem_locations = subset(stem_locations, select = -c(treeID))
  crowns = sf::st_join(crowns, stem_locations)
  crowns = sf::st_difference(crowns)
  crowns = subset(crowns, select = -c(layer))
  
  ### Add height summaries
  message("Extracting height summaries for each crown ... ")
  mean_crown_ht_m = exactextractr::exact_extract(input_chm, crowns, fun = "mean")
  median_crown_ht_m = exactextractr::exact_extract(input_chm, crowns, fun = "median")
  min_crown_ht_m = exactextractr::exact_extract(input_chm, crowns, fun = "min")
  crowns = cbind(crowns, mean_crown_ht_m, median_crown_ht_m, min_crown_ht_m)
  
  ### Write the stem crowns to the disk
  message("Writing the crowns to the disk ... ")
  setwd(config$working_spatial_dir)
  sf::st_write(crowns, "bottom_up_detected_crowns.gpkg", quiet = TRUE, append = FALSE)
  
  ### Get the total time
  end_time = Sys.time()
  total_time = difftime(end_time, start_time, units = c("mins"))
  message("Total bottom-up crown delineation took ", total_time, " minutes ... ")
  
  
}

### Detect trees using bottom up seeds and top down seeds 
wrapper_hybrid_crown_delineation_missing_dbh_prediction = function(config){
  
  ###_________________________________________###
  ### Detect tree tops using top down methods ###
  ###_________________________________________###
  
  master_start_time = Sys.time()
  setwd(config$working_spatial_dir)
  message("Reading in the top down detected crowns ... ")
  top_down_crowns = sf::st_read("top_down_detected_crowns.gpkg", quiet = TRUE)
  
  ###__________________________________________###
  ### Detect tree tops using bottom up methods ###
  ###__________________________________________###
  
  setwd(config$working_spatial_dir)
  message("Reading in the bottom up detected crowns ... ")
  bottom_up_crowns = sf::st_read("bottom_up_detected_crowns.gpkg", quiet = TRUE)
  
  ### Read in the stem locations 
  setwd(config$working_spatial_dir)
  message("Reading in the stem locations ... ")
  stem_locations = sf::st_read("bottom_up_detected_stem_locations.gpkg", quiet = TRUE)
  
  ###________________________________________________________###
  ### Join the Top down crowns with the stem location points ###
  ###________________________________________________________###
  
  ### Join the top down crowns with the stem location points
  print(paste0("Combining top down crowns with stem locations ... "))
  top_down_crowns_joined_stem_locations = sf::st_join(top_down_crowns, stem_locations)
  
  ### Get the top down crowns without stems
  top_down_crowns_no_stems = top_down_crowns_joined_stem_locations[is.na(top_down_crowns_joined_stem_locations$radius_m),]
  top_down_crowns_no_stems
  
  ###_________________________________________________###
  ### Generate Local Model of DBH - crown area/height ###
  ###_________________________________________________###
  
  ### Prepare training dataset for RF modeling
  print(paste0("Preparing to model missing stem locations ... "))
  bottom_up_crowns_no_geom = sf::st_drop_geometry(bottom_up_crowns)
  training_dataset = subset(bottom_up_crowns_no_geom, select = c(radius_m, crown_area_m2, tree_height_m, 
                                                                 mean_crown_ht_m, median_crown_ht_m, min_crown_ht_m))
  
  ### Run a randomForest model to predict DBH using various crown predictors
  print(paste0("Running random forest model to predict radius_m for crowns ... "))
  stem_prediction_model = randomForest::randomForest(radius_m ~ ., data = training_dataset)
  stem_prediction_model
  plot(stem_prediction_model$predicted ~ training_dataset$radius_m)
  rmse = Metrics::rmse(training_dataset$radius_m, stem_prediction_model$predicted)
  mae = Metrics::mae(training_dataset$radius_m, stem_prediction_model$predicted)
  print(paste0("Radius Model has a root mean square error of ", rmse*100, " cm ... "))
  print(paste0("Radius Model has a mean absoulte error of ", mae*100, " cm ... "))
  
  ###___________________________________________________________________###
  ### Predict missing radius values for the top down crowns with no DBH ###
  ###___________________________________________________________________###
  
  ### Predict the missing radius values 
  print(paste0("Predicting missing radius values for top down crowns with no stems ... "))
  top_down_crowns_no_stems_no_geom = sf::st_drop_geometry(top_down_crowns_no_stems)
  prediction_dataset = subset(top_down_crowns_no_stems_no_geom, select = c(crown_area_m2, tree_height_m.x, mean_crown_ht_m,median_crown_ht_m, min_crown_ht_m))
  colnames(prediction_dataset) = c("crown_area_m2", "tree_height_m", "mean_crown_ht_m", "median_crown_ht_m", "min_crown_ht_m")
  radius_m = predict(stem_prediction_model, prediction_dataset)
  radius_m
  
  ###_____________________________________________________________###
  ### Engineer missing features for top down crowns with no stems ###
  ###_____________________________________________________________###
  
  ### Replace the new radius values and derivatives in place of NULL data
  print(paste0("Generating additional features for top down crowns with no stems ... "))
  radius_error_m = "NA"
  dbh_m = radius_m*2
  dbh_cm = dbh_m*100
  basal_area_m2 = pi * (radius_m)^2
  basal_area_ft2 = basal_area_m2 * 10.764
  
  ### Replace the missing data for 
  top_down_crowns_no_stems$radius_m = radius_m
  top_down_crowns_no_stems$radius_error_m = radius_error_m
  top_down_crowns_no_stems$dbh_m = dbh_m
  top_down_crowns_no_stems$dbh_cm = dbh_cm
  top_down_crowns_no_stems$basal_area_m2 = basal_area_m2
  top_down_crowns_no_stems$basal_area_ft2 = basal_area_ft2
  top_down_crowns_no_stems_centroids = sf::st_centroid(top_down_crowns_no_stems)
  top_down_crowns_no_stems$condition = rep("predicted_stem", nrow(top_down_crowns_no_stems_centroids))
  
  ###__________________________________________________________________###
  ### Create fake stem locations for the top down crowns with no stems ###
  ###__________________________________________________________________###
  
  print(paste0("Generating predicted stem locations ... "))
  top_down_crowns_no_stems_predicted_stem_coords = data.frame(sf::st_coordinates(top_down_crowns_no_stems_centroids))
  treeID = paste0(round(top_down_crowns_no_stems_predicted_stem_coords$X,1), "_", round(top_down_crowns_no_stems_predicted_stem_coords$Y,1))
  condition = rep("predicted_stem", nrow(top_down_crowns_no_stems_centroids))
  predicted_stem_locations = subset(top_down_crowns_no_stems_centroids, select = c(tree_height_m.x, radius_m,radius_error_m, dbh_m, dbh_cm, basal_area_m2, basal_area_ft2))
  predicted_stem_locations = cbind(treeID, predicted_stem_locations, condition)
  predicted_stem_locations = sf::st_as_sf(predicted_stem_locations)
  predicted_stem_locations
  
  ### Write the predicted stem locations to the disk
  setwd(config$working_spatial_dir)
  sf::st_write(predicted_stem_locations, dsn = "predicted_stem_locations.gpkg", append = FALSE, quiet = TRUE)
  predicted_stem_locations = sf::st_read("predicted_stem_locations.gpkg", quiet = TRUE)
  predicted_stem_locations
  
  ###___________________________________________________________________________________________________________###
  ### Re-run the bottom up crown delineation using the predicted stem locations and the detected stem locations ###
  ###___________________________________________________________________________________________________________###
  
  ### Combine the predicted and detected stem locations
  stem_locations = subset(stem_locations, select = -c(stem_x, stem_y))
  colnames(predicted_stem_locations) = c("treeID", "tree_height_m", "radius_m", "radius_error_m", "dbh_m", "dbh_cm", "basal_area_m2", "basal_area_ft2", "condition", "geom")
  combined_stem_locations = rbind(stem_locations, predicted_stem_locations)
  
  ### Buffer the combined stem locations by Radius_m
  combined_stem_locations_buff = sf::st_buffer(combined_stem_locations, dist = combined_stem_locations$radius_m)
  
  ###_________________________###
  ### Write files to the disk ###
  ###_________________________###
  
  print(paste0("Writing spatial files to the disk ... "))
  setwd(config$delivery_spatial_dir)
  sf::st_write(combined_stem_locations_buff, "final_stem_locations_dbh.gpkg", append = FALSE, quiet = TRUE)
  sf::st_write(combined_stem_locations, "final_stem_locations.gpkg", append = FALSE, quiet = TRUE)
  
  ### Get the total function time
  master_end_time = Sys.time()
  master_total_time = difftime(master_end_time, master_start_time, units = c("mins"))
  print(paste0("Total stem seed hybridization complete in ", master_total_time, " minutes ..."))
  
}

### New function to detect crowns bottom up, independent from main pipeline
detect_final_crowns = function(config, desired_chm_res, window_size, minimum_height, min_crown_size_m2){
  
  ### Read in the detected stem locations
  start_time = Sys.time()
  
  ### Read in the chm
  setwd(config$delivery_spatial_dir)
  desired_chm_name = paste0("master_chm_raster_", desired_chm_res, "m.tif")
  message("Reading in ", desired_chm_name, " ... ")
  input_file_path = paste0(config$delivery_spatial_dir, "/", desired_chm_name)
  input_chm = terra::rast(input_file_path)
  input_chm
  
  ## Read in the stems
  message("Reading in the final stem location points ... ")
  setwd(config$delivery_spatial_dir)
  stem_locations = sf::st_read("final_stem_locations.gpkg", quiet = TRUE)
  combined_stem_locations = sf::st_read("final_stem_locations.gpkg", quiet = TRUE)
  
  ### Create Seeds object for delineation
  message("Preparing stem locations for crown delineation ... ")
  input_seeds = subset(stem_locations, select = c(tree_height_m))
  colnames(input_seeds) = c("Z", "geometry")
  treeID = rep(1:nrow(input_seeds))
  input_seeds = cbind(treeID, input_seeds)
  input_seeds
  
  ### Use the tree tops to delineate crowns using MCWS from ForestTools
  message("Detecting crowns from stem location seeds ... ")
  input_chm_raster = raster::raster(input_chm)
  crowns = ForestTools::mcws(input_seeds, input_chm_raster, minHeight = minimum_height, format = "raster")
  crowns
  
  ### Get the treeID fixed for the input seeds
  message("Cleaning up the delineated crowns ... ")
  input_seeds_coords = as.data.frame(sf::st_coordinates(input_seeds))
  treeID = paste0(round(input_seeds_coords$X, 1), "_", round(input_seeds_coords$Y, 1))
  input_seeds = subset(input_seeds, select = -c(treeID))
  input_seeds = cbind(input_seeds, treeID)
  input_seeds
  
  ### Convert crown raster to terra rast, then polygons, then to Sf
  crowns = terra::rast(crowns)
  crowns = terra::as.polygons(crowns)
  crowns = terra::simplifyGeom(crowns)
  crowns = terra::fillHoles(crowns)
  crowns = sf::st_as_sf(crowns)
  crowns = sf::st_buffer(crowns, 0)
  #crowns = sf::st_difference(crowns)
  
  ### Get the crown area, then remove super small crowns
  message("Getting crown area of polygons ... ")
  crown_area_m2 = as.numeric(sf::st_area(crowns))
  crowns = cbind(crowns, crown_area_m2)
  crowns = crowns[crowns$crown_area_m2 > min_crown_size_m2,]
  
  ### Join the crowns with the seeds to append data, remove Nulls
  message("Joining crowns with input tree top seeds ... ")
  stem_locations = subset(stem_locations, select = -c(treeID))
  crowns = sf::st_join(crowns, stem_locations)
  crowns = sf::st_difference(crowns)
  crowns = subset(crowns, select = -c(layer))
  
  ### Add height summaries
  message("Extracting height summaries for each crown ... ")
  mean_crown_ht_m = exactextractr::exact_extract(input_chm, crowns, fun = "mean")
  median_crown_ht_m = exactextractr::exact_extract(input_chm, crowns, fun = "median")
  min_crown_ht_m = exactextractr::exact_extract(input_chm, crowns, fun = "min")
  crowns = cbind(crowns, mean_crown_ht_m, median_crown_ht_m, min_crown_ht_m)
  
  ### Append the tree ID from the stem locations to the crowns
  message("Cleaning up final crowns ... ")
  treeID = subset(combined_stem_locations, select = c(treeID))
  crowns = sf::st_join(crowns, treeID)
  crowns = sf::st_difference(crowns)
  
  ### Write the stem crowns to the disk
  message("Writing the final crowns to the disk ... ")
  setwd(config$delivery_spatial_dir)
  sf::st_write(crowns, "final_detected_crowns.gpkg", quiet = TRUE, append = FALSE)
  
  ### Get the total time
  end_time = Sys.time()
  total_time = difftime(end_time, start_time, units = c("mins"))
  message("Total final crown delineation took ", total_time, " minutes ... ")
  
  
}

### New function to colorize las files based on input type
colorize_input_las = function(input_las, desired_color){
  
  color_ramp_rgb = paste(as.vector(col2rgb(desired_color)), collapse = " ")
  color_ramp_rgb = stringr::str_split(color_ramp_rgb, pattern = " ")  
  color_ramp_rgb = as.data.frame(color_ramp_rgb)  
  color_ramp_rgb = t(color_ramp_rgb)
  rownames(color_ramp_rgb) = NULL
  color_ramp_rgb = as.data.frame(color_ramp_rgb)
  colnames(color_ramp_rgb) = c("R", "G", "B")
  R = rep(as.integer(color_ramp_rgb$R), nrow(input_las@data))    
  G = rep(as.integer(color_ramp_rgb$G), nrow(input_las@data))  
  B = rep(as.integer(color_ramp_rgb$B), nrow(input_las@data)) 
  
  ### Use the lidR functions to colorize the point cloud
  input_las = lidR::add_lasrgb(input_las, R = R, G = G, B = B)   
  return(input_las)
  
}

### New function to crop each crown to each canopy polygon, colorize, write to disk
crop_crowns_by_id_and_colorize_stems_and_veg = function(config, las_grid, colorize_input_las, stem_color_hex, veg_color_hex, ground_color_hex, use_bottom_up_crowns){
  
  stem_color_hex = "#8B4513"
  veg_color_hex = "#228B22"
  ground_color_hex = "#EEE8AA"
  
  ###___________________________###
  ### Read in the desired files ###
  ###___________________________###
  
  ### Read in the master crown file
  print(paste0("Initializing tree crown crop and colorization algorithm ... "))
  
  ### If use bottom up crowns == FALSE, use combined crowns
  if(use_bottom_up_crowns == FALSE){  
    
    setwd(config$delivery_spatial_dir)
    master_crowns = sf::st_read("final_detected_crowns.gpkg", quiet = TRUE)
    master_crowns
    
  }
  
  ### If use bottom up crowns == TRUE, use bottom up crowns
  if(use_bottom_up_crowns == TRUE){  
    
    setwd(config$working_spatial_dir)
    master_crowns = sf::st_read("bottom_up_crowns.gpkg", quiet = TRUE)
    master_crowns
    
  }
  
  
  
  ### Read in the classified las files as a catalog
  las_stem_ctg = lidR::readTLSLAScatalog(config$las_stem_dir)
  las_stem_ctg
  
  ###_____________________________###
  ### Initialize parallel session ###
  ###_____________________________###
  
  print(paste0("Processing ", nrow(master_crowns), " crown files ... "))
  start_time = Sys.time()
  cores = detectCores()
  print(paste0("Starting parallel cluster on ", cores-1, " cores ... "))
  cluster = makeCluster(cores-1)
  registerDoParallel(cluster)
  foreach(i=1:nrow(master_crowns), .packages = c("lidR"), .errorhandling = "remove", .inorder = FALSE) %dopar% {
    
    ### Get the desired crown file
    des_crown = master_crowns[i,]
    des_crown
    
    ### Has the crown already been cropped/colored?
    file_to_check = paste0(config$las_tree_dir, "/", i, ".laz")
    does_file_exsist = file.exists(file_to_check)
    does_file_exsist
    
    ### If file exsists, skip
    if(does_file_exsist == TRUE){return(NULL)}
    
    ### If file doesnt exsist, crop the file
    if(does_file_exsist == FALSE){
      
      ### Crop the crown file from the las catalog
      cropped_crown = lidR::clip_roi(las_stem_ctg, des_crown)
      
      ### Drop points low to the ground
      cropped_crown = lidR::filter_poi(cropped_crown, Z > 0.1)
      
      ### Pull the veg and stems from the cropped crown
      veg = lidR::filter_poi(cropped_crown, Classification == 5)
      stem = lidR::filter_poi(cropped_crown, Classification == 4)
      
      ### Get some checks
      veg_empty = lidR::is.empty(veg)
      stem_empty = lidR::is.empty(stem)
      
      ###______________________________________________________________________###
      ### If stems and crowns are not empty, color them then write to the disk ###
      ###______________________________________________________________________###
      
      if(veg_empty == FALSE && stem_empty == FALSE){
        
        ### Get random color for the veg
        des_veg_color = randomcoloR::randomColor(count = 1, hue = c("green"), luminosity = c("dark"))
        
        ### Colorize the veg points
        veg = colorize_input_las(veg, desired_color = des_veg_color)
        
        ### Get random colors for the stems
        des_stem_color = randomcoloR::randomColor(count = 1, hue = c("orange"), luminosity = c("dark"))
        
        ### Colorize the stem points
        stem = colorize_input_las(stem, desired_color = des_stem_color)
        
        ### Combine the colored stems and veg
        combined = rbind(veg, stem)
        
        ### Write the colored crown to the disk
        setwd(config$las_tree_dir)
        out_name = paste0(des_crown$treeID,".laz")
        lidR::writeLAS(combined, out_name)
        return(NULL)
        
      }
      
      ###___________________________________________________________________________________###
      ### If the veg isnt empty, and the stems are empty, color the veg, then write to disk ###
      ###___________________________________________________________________________________###
      
      if(veg_empty == FALSE && stem_empty == TRUE){
        
        ### Get random color for the veg
        des_veg_color = randomcoloR::randomColor(count = 1, hue = c("green"), luminosity = c("dark"))
        
        ### Colorize the veg points
        veg = colorize_input_las(veg, desired_color = des_veg_color)
        
        ### Write the colored crown to the disk
        setwd(config$las_tree_dir)
        out_name = paste0(des_crown$treeID,".laz")
        lidR::writeLAS(veg, out_name)
        return(NULL)
        
      }
      
    }
    
  }
  stopCluster(cluster)
  end_time = Sys.time()
  total_crop_time = difftime(end_time, start_time, units = c("mins"))
  print(paste0("Total crop/colorization took ", total_crop_time, " minutes ... "))
  
  ###___________________________________________###
  ### Loop through the cropped crowns and merge ###
  ###___________________________________________###
  
  las_list = list.files(config$las_tree_dir, pattern = ".las")
  laz_list = list.files(config$las_tree_dir, pattern = ".laz")
  lidar_list = append(las_list, laz_list)
  lidar_list
  
  print(paste0("Merging ", length(lidar_list), " tree las files ... "))
  start_time = Sys.time()
  cores = detectCores()
  print(paste0("Starting parallel cluster on ", cores-1, " cores ... "))
  cluster = makeCluster(cores-1)
  registerDoParallel(cluster)
  merged_data_las = foreach(i=1:length(lidar_list)) %dopar% {
    
    setwd(config$las_tree_dir)
    des_file = lidar_list[i]
    las = lidR::readTLSLAS(des_file)
    data = las@data
    return(data)
    
  }
  stopCluster(cluster)
  
  merged_data = data.table::rbindlist(merged_data_las)
  las = lidR::LAS(merged_data)
  st_crs(las) = st_crs(las_stem_ctg)
  las
  
  ### Write the las file to the disk
  setwd(config$delivery_las_dir)
  lidR::writeLAS(las, "master_classified_trees.las")
  
}

### Function to calculate basal area from final stem dataset
get_final_tree_stats = function(config){
  
  message(" --- Starting final tree stats pipeline --- ")
  master_start = Sys.time()
  setwd(config$delivery_spatial_dir)
  
  ### Read in the final stem dataset
  message("Reading in the final stem locations ... ")
  final_stems = sf::st_read("final_stem_locations.gpkg", quiet = TRUE)
  final_stems
  
  ### Read in the final canopy dataset
  message("Reading in the final crown dataset ... ")
  final_crowns = sf::st_read("final_detected_crowns.gpkg", quiet = TRUE)
  final_crowns
  
  ### Read in the summary stats from height normalization
  setwd(config$delivery_stats_dir)
  normalization_stats = read.csv("02_point_cloud_classification_normalization_stats.csv")
  head(normalization_stats)
  
  ###______________________________________________###
  ### Get the basal area for the processed dataset ###
  ###______________________________________________###
  
  ### Convert the stem measurement diameter to inches
  message("Getting basal area statistics ... ")
  dbh_inches = final_stems$dbh_cm/2.54
  
  ### Get basal area for each tree
  basal_area_square_ft = (dbh_inches^2) * 0.005454
  
  ### Get the sum of basal area
  sum_basal_area_square_ft = sum(basal_area_square_ft)
  sum_basal_area_square_ft
  
  ### Get the sum of basal area in acres
  sum_basal_area_acres = sum_basal_area_square_ft/43560
  sum_basal_area_acres
  
  ###___________________________________###
  ### Get the total tree count and area ###
  ###___________________________________###
  
  message("Getting tree statistics ... ")
  total_tree_count = nrow(final_crowns)
  total_tree_count
  
  ### Get the sum crown area
  sum_crown_area_m2 = sum(final_crowns$crown_area_m2)
  sum_crown_area_m2  
  
  ### Convert to square feet
  sum_crown_area_ft2 = sum_crown_area_m2*10.764
  sum_crown_area_ft2
  
  ### Convert to acres
  sum_crown_area_acres = sum_crown_area_m2/4047
  sum_crown_area_acres
  
  ### Get the max tree height
  max_tree_height = max(final_crowns$tree_height_m, na.rm = TRUE)
  max_tree_height
  
  ### Get the median tree height
  median_tree_height = median(final_crowns$tree_height_m, na.rm = TRUE)
  median_tree_height
  
  ### Get the mean tree height
  mean_tree_height = mean(final_crowns$tree_height_m, na.rm = TRUE)
  mean_tree_height
  
  ###________________________###
  ### Calculate tree density ###
  ###________________________###
  
  message("Calculating tree density per acre ... ")
  las_area_acres = normalization_stats$las_area_acres
  trees_per_acre = total_tree_count/las_area_acres
  trees_per_acre
  
  ###_______________________________###
  ### Compile final stats dataframe ###
  ###_______________________________###
  
  message("Compiling master stats dataframe ... ")
  final_stats_dataframe = cbind(total_tree_count, trees_per_acre, max_tree_height, median_tree_height, mean_tree_height,
                                sum_crown_area_ft2, sum_crown_area_acres, sum_basal_area_square_ft, sum_basal_area_acres)
  
  final_stats_dataframe = data.frame(final_stats_dataframe)
  final_stats_dataframe
  
  ###___________________________________###
  ### Write the final stats to the disk ###
  ###___________________________________###
  
  message("Writing the final stats dataframe to the disk ... ")
  setwd(config$delivery_spatial_dir)
  write.csv(final_stats_dataframe, "final_tree_detection_stats.csv")
  
  ###________________###
  ### Wrap things up ###
  ###________________###
  
  master_end = Sys.time()
  master_total = difftime(master_end, master_start, units = c("mins"))
  message(" --- Final tree stats pipeline complete in ", master_total, " minutes ---")
  return(final_stats_dataframe)
  
}

###_______________________________###
### Configure project directories ###
###_______________________________###

### Set up the project directory structure
total_start = Sys.time()
config = create_project_structure(rootdir)

### Read in the las files, check the number of points and CRS
las_ctg = read_las_as_ctg(config)
las_ctg
mapview(las_ctg@data$geometry)

###__________________________________________________________###
### Set parameters for tiling, buffering, and tree detection ###
###__________________________________________________________###

### Set the extent of the tile grid
desired_tile_res = 50

### Set the desired buffer size
desired_buffer_size = 10

### Set the window size for top down tree detection
window_size = 3.5

### Set the minimum height for crown delineation
minimum_height = 1

### Set the minimum crown size (m^2) to be retained after delineation
min_crown_size_m2 = 3

### Set the maximum dbh size (meters)
dbh_max_size_m = 1.5

###_______________________________________________________###
### Run the function to generate a tile grid for cropping ###
###_______________________________________________________###

### Generate the grid overlay on top of the las catalog geometry
las_grid = generate_grid_over_extent(las_ctg, desired_tile_res)
las_grid_buff = sf::st_buffer(las_grid, desired_buffer_size)
mapview(las_grid_buff) + las_ctg@data$geometry

###_______________________________###
### Tile the original point cloud ###
###_______________________________###

create_lax_for_tiles(config$input_las_dir)
tiled_grid = new_tile_las_to_grid_foreach(config, desired_buffer_size)
mapview(tiled_grid)
create_lax_for_tiles(config$las_tile_dir)

###______________________________________________________###
### Next, classify ground and height normalize each tile ###
###______________________________________________________###

height_norm_grid = classify_ground_normalize(config, las_grid, want_to_classify_ground = TRUE)
mapview(height_norm_grid)
create_lax_for_tiles(config$las_ground_tile_dir)
create_lax_for_tiles(config$las_norm_tile_dir)

###___________________________________________###
### Rasterize the tiled las to get a DEM file ###
###___________________________________________###

rasterize_tiles_to_dem(config, des_dem_res = 3, calculate_extent = FALSE)

###_____________________________________________###
### Rasterize the normalized tiles to CHM tiles ###
###_____________________________________________###

rasterize_tiles_to_chm(config, des_chm_res = 0.25, max_height_threshold = 60, calculate_extent = FALSE)

###_____________________________________________________###
### Rasterize the stem section at DBH to stem CHM tiles ###
###_____________________________________________________###

rasterize_tiles_to_stem_chm(config, des_stem_chm_res = 0.07, min_z = 1.2, max_z = 1.4, calculate_extent = FALSE)

###_______________________________________________________________###
### Detect trees via stem search algorithm, then delineate crowns ###
###_______________________________________________________________###

detect_stems_within_tiles(config, dbh_max_size_m)
create_lax_for_tiles(config$las_stem_dir)

###_______________________________________###
### Detect crowns using top down approach ###
###_______________________________________###

detect_crowns_top_down(config, desired_chm_res = 0.25, window_size, minimum_height, min_crown_size_m2)

###________________________________________###
### Detect crowns using bottom up approach ###
###________________________________________###

detect_crowns_bottom_up(config, desired_chm_res = 0.25, window_size, minimum_height, min_crown_size_m2)

###_____________________________________________________________________###
### Run the hybrid crown delineation method with missing dbh prediction ###
###_____________________________________________________________________###

wrapper_hybrid_crown_delineation_missing_dbh_prediction(config)

###______________________________________###
### Run the final tree detection methods ###
###______________________________________###

detect_final_crowns(config, desired_chm_res = 0.25, window_size, minimum_height, min_crown_size_m2)

###___________________________________________###
### Run the crop and colorize by tree ID step ###
###___________________________________________###

crop_crowns_by_id_and_colorize_stems_and_veg(config, las_grid, colorize_input_las, stem_color_hex, veg_color_hex, ground_color_hex,
                                             use_bottom_up_crowns = FALSE)

###_____________________________________###
### Get final tree detection statistics ###
###_____________________________________###

final_stats = get_final_tree_stats(config)
final_stats

###_______________________________###
### Get the total processing time ###
###_______________________________###

total_end = Sys.time()
total_master = difftime(total_end, total_start, units = c("mins"))
print(paste0("Total tree pipeline took ", total_master, " minutes ... "))

```